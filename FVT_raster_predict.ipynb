{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABOUT\n",
    "__Author__: Pat McCornack\n",
    "\n",
    "__Date__: 4/15/2024\n",
    "\n",
    "__Purpose:__ Script to apply a trained model to predict FVT values. Outputs a raster of predicted FVT values across the bpa service territory. \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.windows import Window\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from joblib import load\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define filepaths\n",
    "local_root_dir = r\"C:\\Users\\mcco573\\OneDrive - PNNL\\Documents\\_Projects\\BPA Wildfire\\Fuel Attributes Model\"\n",
    "pnnl_root_dir = r\"\\\\pnl\\projects\\BPAWildfire\\data\\Landfire\\fuels_modeling\\Fuel Attributes Model\"\n",
    "\n",
    "active_root_dir = pnnl_root_dir\n",
    "\n",
    "\n",
    "paths_dict = {\n",
    "    'data_dir' : os.path.join(active_root_dir, r'..\\LF_raster_data\\bpa_service_territory'),\n",
    "    'out_base_dir' : os.path.join(active_root_dir, r'model_outputs\\geospatial'),\n",
    "    'new_dir_name' : 'LF22_Pred_FVT',  # Name of created directory to hold results - will have datetime appended to it\n",
    "    'ref_data_dir' : os.path.join(active_root_dir, r'..\\LF_raster_data\\_tables'),\n",
    "    'model_dir' : os.path.join(active_root_dir, 'models'),\n",
    "    'model_fname' : \"LF22_FVT_HGBC_model_2024-05-10_16-49-07\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Functions__\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Make Directory__\n",
    "Creates a directory where data will be output - labeled with the datetime that the script is run. Returns name of directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir(base_dir, new_dir_name):\n",
    "        \"\"\"\n",
    "        Create a directory named using the current datetime.\n",
    "        Returns:\n",
    "        - Name of the directory as a string\n",
    "        \"\"\"\n",
    "\n",
    "        datetime = dt.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        output_dir = os.path.join(base_dir, new_dir_name + \"_\" + datetime)\n",
    "\n",
    "        os.makedirs(output_dir)\n",
    "        return output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Feature Engineering__\n",
    "Use values from the rasters to create new features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Reference Data\n",
    "Use the LANDFIRE csv tables to create dictionaries to be used to map raster layer values to other features.\n",
    "1. Separate LF22_FDST into separate features for type, severity, and time since disturbance.\n",
    "2. Map the BPS value to BPS_NAME in order to reduce cardinality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_data_dir = paths_dict['ref_data_dir']\n",
    "def read_ref_data(ref_data_dir=ref_data_dir):\n",
    "    \"\"\"\n",
    "    Creates dictionaries from LF attributes tables that are used to map layer values to other features. Returns a dictionary of dictionaries. \n",
    "    \"\"\"\n",
    "    data_dir = ref_data_dir\n",
    "    BPS_fname = \"LF20_BPS_220.csv\"\n",
    "\n",
    "    # Create empty dictionary\n",
    "    LF_ref_dicts = {}\n",
    "\n",
    "    # Get BPS reference dictionary\n",
    "    BPS_df = pd.read_csv(os.path.join(data_dir, BPS_fname))\n",
    "    LF_ref_dicts[\"BPS_NAME\"] = dict(BPS_df[['VALUE', 'BPS_NAME']].values)\n",
    "   \n",
    "    return LF_ref_dicts                        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Features\n",
    "Use dictionaries created using read_ref_data to map raster values to new features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_features(df, feature_list = ['BPS_NAME']):\n",
    "    \"\"\"\n",
    "    Joins in additional features using LF attribute tables. \n",
    "    \"\"\"\n",
    "    \n",
    "    LF_ref_dicts = read_ref_data()\n",
    "    \n",
    "    source_layers = {\n",
    "        'BPS_NAME' : 'BPS', \n",
    "    }\n",
    "\n",
    "    for feature in feature_list:\n",
    "        df[feature] = df[source_layers[feature]].map(LF_ref_dicts[feature]).copy()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Preprocess window dataframe__\n",
    "Prepares the data to be run through the model. Separates out null and non-disturbed. Returns a dictionary with: \n",
    "1. A clean dataframe to be run through the model. \n",
    "2. A dataframe of the dropped observations to be rejoined to model predictions. This allows for the data to be reshaped to a 2D numpy array and written as a raster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(df):\n",
    "    \"\"\"\n",
    "    Prepares data to run model on.\n",
    "    Input: \n",
    "    - A dataframe containing created using the flattened numpy arrays returned from reading in the raster chunks. \n",
    "    Returns: \n",
    "    - Clean dataframe without NULL data or non-burnable F40 Classes \n",
    "    - Dataframe with the dropped observations - to be reappended after prediction\n",
    "    \"\"\"\n",
    "    # Join in additional features\n",
    "    df = join_features(df, feature_list = ['BPS_NAME'])\n",
    "\n",
    "    # Remove -9999/-1111 (Null values)\n",
    "    null_points = df[(df.isin([-1111, -9999])).any(axis=1)]  # Find rows with -1111/-9999 in any column\n",
    "    df = df.drop(null_points.index, axis=0)  # Drop those rows\n",
    "    \n",
    "    # Remove non-disturbed points\n",
    "    non_disturbed = df.loc[df['LF22_FDST'] == 0]\n",
    "    df = df.drop(non_disturbed.index, axis=0)\n",
    "\n",
    "    # Filter out agricultural and developed points\n",
    "    developed_fvt = list(range(20,33)) + list(range(2901,2906))\n",
    "    ag_fvt = [80, 81, 82] + list(range(2960, 2971))\n",
    "    fvt_filter = developed_fvt + ag_fvt\n",
    "\n",
    "    ag_dev = df.loc[df['LF20_FVT'].isin(fvt_filter)]\n",
    "    df = df.drop(ag_dev.index, axis=0)\n",
    "\n",
    "    # Join the filtered values together so they can be readded later\n",
    "    dropped = pd.concat([null_points, non_disturbed, ag_dev], axis=0)\n",
    "    dropped = dropped[['LF20_FVT']].rename(columns={'LF20_FVT':'FVT_Pred'})  # Renamed to match with predictions\n",
    "    \n",
    "    return df, dropped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Predict FVT__\n",
    "### Read Window\n",
    "This function is used to read in chunks of the rull raster to be processed. The raster data is stored as blocks with height=1 and width=41855 (the raster width), so we read in chunks composed of these blocks (e.g. 1000 blocks at a time). This corresponds to the row_slice argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_read(ras, row_slice):\n",
    "  \"\"\"\n",
    "  Reads in a subset (window) of the data to be processed.\n",
    "  Inputs:\n",
    "  - ras: Raster object read in using rasterio\n",
    "  - row_slice: Used to define the window height - in the form (row_start, row_end). \n",
    "\n",
    "  Returns:\n",
    "  - data: The data in the window as a 2D numpy array\n",
    "  - win: The Window object used to define the subset of the data. \n",
    "  - win_transform: The affine transform associated with the window. Used to update the metadata of the output of that chunk. \n",
    "  \"\"\"\n",
    "  \n",
    "  with rasterio.open(ras) as src:\n",
    "    col_slice = (0, src.width)  # Define row slice based on block size\n",
    "    win = Window.from_slices(row_slice, col_slice) \n",
    "    data = src.read(window=win)\n",
    "    win_transform = src.window_transform(win)\n",
    "    \n",
    "  return data, win, win_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Apply Trained Model__ \n",
    "Applies a trained model to the prepared data to predict FVT for each observation (i.e. pixel). After making predictions, rejoins the previously dropped observations so that the dataframe can be reshaped to a 2D numpy array and written to a raster. The index is used to keep track of relative pixel locations in the dataframe. This function returns a dataframe with predictions for each non-null and burnable observation. \n",
    "\n",
    "The model was not trained using null (-9999, -1111), non-disturbed, or agricultural/developed classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_FVT(model, df):\n",
    "    \"\"\"\n",
    "    Predicts F40 class given a trained model and data to predict on.\n",
    "    Returns:\n",
    "    - A dataframe of predicted F40 values joined to the previously dropped values. \n",
    "    \"\"\"\n",
    "    # Prep the data - get the a clean dataframe (i.e. no NULL data/nonburnable classes) and dropped observations\n",
    "    clean_df, dropped = data_prep(df)\n",
    "\n",
    "    # Get list of predictors for run\n",
    "    predictors = clean_df.columns.tolist()\n",
    "    \n",
    "    x_test = clean_df[predictors].copy()\n",
    "\n",
    "    # Run model to predict\n",
    "    # If clean_df is empty, then all values were NULL and are in dropped\n",
    "    if clean_df.shape[0] > 0:\n",
    "        y_pred = model.predict(x_test)\n",
    "    else:\n",
    "        return dropped\n",
    "    \n",
    "    # Join the dropped observations back in \n",
    "    # This allows the result dataframe to be reshaped back to a raster\n",
    "    df = pd.DataFrame({\"FVT_Pred\" : y_pred},\n",
    "                       index=x_test.index)\n",
    "    df = pd.concat([dropped, df])\n",
    "    df.sort_index(inplace=True)\n",
    "\n",
    "    # Return predictions\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_predict(row, model_fpath, win_height, raster_dict, ras_shape, out_dir, out_meta):\n",
    "\n",
    "    model = load(model_fpath)\n",
    "\n",
    "    row_start = row\n",
    "    row_end = row + win_height  # This is also the row_offset of the window\n",
    "\n",
    "    # make sure slice doesn't exceed row/col dims\n",
    "    if row_end > ras_shape[0]:\n",
    "        row_end = ras_shape[0]\n",
    "\n",
    "    # Define the window to be processed\n",
    "    row_slice = (row_start, row_end)\n",
    "\n",
    "    data_dict = {}\n",
    "\n",
    "    # For the current window, load data from each rasters\n",
    "    for var, fpath in raster_dict.items():\n",
    "        data_chunk, data_win, data_transform = windowed_read(fpath, row_slice)\n",
    "        data_dict[var] = data_chunk.ravel()\n",
    "\n",
    "    # Create a dataframe from the dictionary of datachunks\n",
    "    df = pd.DataFrame(data_dict)\n",
    "\n",
    "    # Look at the window currently processing\n",
    "    clear_output()\n",
    "\n",
    "    datetime = dt.datetime.now().strftime('%H-%M-%S-%f')\n",
    "    out_file = f\"data_chunk_{datetime}.tif\"\n",
    "    #print(f\"Row Slice: {row_slice}\")  \n",
    "    #print(f\"Writing {out_file}.\")\n",
    "    #print(f\"Processing window {i} of {floor(ras_shape[0] / win_height)}\")\n",
    "\n",
    "    # Run model to predict F40 Classes for window \n",
    "    out_arr = predict_FVT(model, df)\n",
    "\n",
    "    # Reshape to 2D\n",
    "    out_arr_np = out_arr.to_numpy()\n",
    "    out_arr_2D = out_arr_np.reshape(data_chunk.shape)\n",
    "    out_arr_2D = out_arr_2D[0]\n",
    "\n",
    "    # update output metadata for chunk\n",
    "    out_meta.update({\n",
    "    'height': out_arr_2D.shape[0],\n",
    "    'width': out_arr_2D.shape[1],\n",
    "    'transform' : data_transform\n",
    "    })\n",
    "\n",
    "    # Write chunk out\n",
    "    datetime = dt.datetime.now().strftime('%H-%M-%S-%f')\n",
    "    out_file = f\"data_chunk_{datetime}.tif\"\n",
    "    with rasterio.open(os.path.join(out_dir, out_file), 'w+', **out_meta) as out:\n",
    "        out.write(out_arr_2D, indexes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Run Model Predictions__\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to either pnnl or local root directory. \n",
    "\n",
    "# Define filepath to model\n",
    "model_fpath = os.path.join(paths_dict['model_dir'],  paths_dict['model_fname'])\n",
    "\n",
    "# Define the source raster file names\n",
    "raster_paths = {\n",
    "    \"LF20_FVT\" : os.path.join(paths_dict['data_dir'], \"LC22_FVT_220_bpa.tif\"),\n",
    "    \"LF22_FDST\" : os.path.join(paths_dict['data_dir'], \"LC22_FDst_230_bpa.tif\"),\n",
    "    \"LF20_FVC\" : os.path.join(paths_dict['data_dir'], \"LC22_FVC_220_bpa.tif\"),\n",
    "    \"LF20_FVH\" : os.path.join(paths_dict['data_dir'], \"LC22_FVH_220_bpa.tif\"),\n",
    "    \"ZONE\" : os.path.join(paths_dict['data_dir'], \"us_lf_zones_bpa.tif\"),\n",
    "    \"ASPECT\" : os.path.join(paths_dict['data_dir'], \"LC20_Asp_220_bpa.tif\"),\n",
    "    \"SLOPE\" : os.path.join(paths_dict['data_dir'], \"LC20_SlpD_220_bpa.tif\"),\n",
    "    \"ELEVATION\" : os.path.join(paths_dict['data_dir'], \"LC20_Elev_220_bpa.tif\"),\n",
    "    \"BPS\" : os.path.join(paths_dict['data_dir'], \"LC22_BPS_220_bpa.tif\")\n",
    "}\n",
    "\n",
    "# Create directory using current datetime to output data chunks to\n",
    "datetime = dt.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')  # Used to name output file\n",
    "out_dir = make_dir(base_dir=paths_dict['out_base_dir'], new_dir_name=paths_dict['new_dir_name'])\n",
    "\n",
    "# Arbitrarily grab metadata from LF20_FVT raster to use for updating output metdata\n",
    "with rasterio.open(raster_paths['LF20_FVT']) as src:\n",
    "  out_meta = src.meta.copy()\n",
    "\n",
    "## Read in data\n",
    "# Open a raster to access its attributes\n",
    "ras = rasterio.open(raster_paths['LF20_FVT'])\n",
    "\n",
    "# Define window height and iteration tracker\n",
    "win_height = 1000  # Number of rows to process at once\n",
    "\n",
    "# Run predict function in parallel\n",
    "Parallel(n_jobs=24)(delayed(window_predict)(row, model_fpath, win_height, raster_paths, ras.shape, out_dir, out_meta) for row in range(0, ras.shape[0], win_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mosaic the Data Chunks\n",
    "Combines the chunks generated above into a single raster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file paths of the generated data chunks\n",
    "raster_fpaths = glob.glob(out_dir + \"/*.tif\")\n",
    "\n",
    "# Get the rasterio dataset objects corresponding to each path\n",
    "src_files_to_mosaic = []\n",
    "for fpath in raster_fpaths:\n",
    "    src = rasterio.open(fpath)\n",
    "    src_files_to_mosaic.append(src)\n",
    "\n",
    "# Merge the data chunks into a single raster\n",
    "mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "\n",
    "# Get the metadata for writing\n",
    "out_meta = src.meta.copy()\n",
    "out_meta.update({\n",
    "    \"driver\" : \"GTiff\",\n",
    "    \"height\" : mosaic.shape[1],\n",
    "    \"width\" : mosaic.shape[2],\n",
    "    \"transform\" : out_trans\n",
    "})\n",
    "\n",
    "# Write out the mosaic raster\n",
    "fname = out_dir + '.tif'\n",
    "with rasterio.open(os.path.join(out_dir, fname), \"w\", **out_meta) as dest:\n",
    "    dest.write(mosaic)\n",
    "\n",
    "print(f\"Raster written to {os.path.join(out_dir, fname)}\")\n",
    "\n",
    "# Delete the chunks\n",
    "#for raster in raster_fpaths:\n",
    "    #os.remove(raster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
