{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABOUT\n",
    "__Author__: Pat McCornack\n",
    "\n",
    "__Date__: 2/21/24\n",
    "\n",
    "__Purpose__: Model Development and Evaluation for FBFM40 classification. Allows the user to iterate through different model types, parameters, and sets of predictors to evaluate which yields the best results. Can also output a model trained on sample points to be used elsewhere. \n",
    "\n",
    "The best performing model to date (3/25/24) is the following:\n",
    "- Model: HGBC (Histogram Based Gradient Boosting Classifier)\n",
    "- Weight: Balanced - This is used to account for class imbalance\n",
    "- Predictors: ['FVT', 'FVC', 'FVH', 'FDST', 'ZONE', 'BPS_FRG_NEW']\n",
    "    - Note that BPS_FRG_NEW is a feature in the LANDFIRE \"Biophysical Setting\" (BpS) layer that was extracted. \n",
    "- F40_GROUP: False - Note that while setting this to true may increase accuracy, we are not convinced that using the F40 \"parent classes\" (e.g. Grass-Shrub) is a valid approach. \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path, listdir, mkdir\n",
    "import datetime as dt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define filepaths\n",
    "\n",
    "paths_dict = {\n",
    "    'LF23_gdb' : r'\\\\pnl\\projects\\BPAWildfire\\data\\Landfire\\fuels_modeling\\F40_modeling\\data\\geodatabases\\LF23_data.gdb',\n",
    "    'LF23_sample_points_fname' : 'LF23_sample_points_100k_3_12_24',\n",
    "    'LF22_sample_points_fname' : 'LF22_sample_points_100k_3_8_24',\n",
    "    'runs_fpath' : r'\\\\pnl\\projects\\BPAWildfire\\data\\Landfire\\fuels_modeling\\F40_modeling\\data\\model_run_dicts\\FRDB_analog_runs.csv',\n",
    "    'model_out_dir' : r\"\\\\pnl\\projects\\BPAWildfire\\data\\Landfire\\fuels_modeling\\F40_modeling\\models\\models_3-18-24\",\n",
    "    'model_output_dir' : r\"\\\\pnl\\projects\\BPAWildfire\\data\\Landfire\\fuels_modeling\\F40_modeling\\model_outputs\\tabular\",\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch categorical features\n",
    "Selects categorical features from a list of predictors. Used for categorical variable encoding. \n",
    "\n",
    "The current implementation simply removes the continuous features from the list of columns and assigns the rest are categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat_features(predictors):\n",
    "    \"\"\"\n",
    "    Returns a list of categorical features to be encoded.\n",
    "    \"\"\"\n",
    "    # Define the noncategorical (i.e. continuous) features\n",
    "    noncat_variables = ['ASPECT', 'SLOPE', 'ELEVATION', 'geometry', 'F40']\n",
    "\n",
    "    # Subset out the categorical features\n",
    "    cat_variables = [x for x in predictors if x not in noncat_variables]\n",
    "\n",
    "    return cat_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variable Encoder\n",
    "Categorical variables must be encoded before being used for the Random Forest. Note that due to HGBC's native encoding support this function is not needed when using that model type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def targetEncoder(sample_points, target):\n",
    "    \"\"\"\n",
    "    Replaces the categorical features in sample_points with encodings using target encoder.\n",
    "    target - target variable feature name (e.g. \"F40\").\n",
    "    \"\"\"\n",
    "\n",
    "    cat_variables = get_cat_features(sample_points)\n",
    "\n",
    "    # Encode the features\n",
    "    enc = TargetEncoder(target_type=\"multiclass\", random_state=1234).set_output(transform=\"pandas\")\n",
    "    enc.fit(sample_points[cat_variables], sample_points[target])  # Fit the encoder\n",
    "    df_trans = enc.transform(sample_points[cat_variables])  # Create the encoded features\n",
    "\n",
    "    # Replace the features with encoded feature in sample_points\n",
    "    sample_points = sample_points.drop(cat_variables, axis=1)\n",
    "    sample_points = pd.concat([sample_points, df_trans], axis=1)\n",
    "    \n",
    "    return sample_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Over-Sampling Function\n",
    "The class representation of the target variable (FBFM40) is heavily imbalanced in the BPA service territory. Random oversampling is one method to address class imbalance - This function will resample minority classes with replacement to create a more balanced class distribution.\n",
    "\n",
    "__Note:__ This increases the size of the dataset and therefore the classifier will require more computational resources/time. While testing we found that over sampling did not provide any significant advantage over using weights to account for class imbalance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overSampler(predictor_df, target_df, seed):\n",
    "    \"\"\"\n",
    "    Oversamples the dataset to correct target class imbalance. Returns the resampled predictors and responses as separate dataframes.\n",
    "    predictor_df - dataframe of features used as predictors.\n",
    "    target_df - dataframe of the target feature (e.g. F40).\n",
    "    \"\"\"\n",
    "\n",
    "    ros = RandomOverSampler(random_state=seed)\n",
    "    pred_resampled, resp_resampled = ros.fit_resample(predictor_df, target_df)\n",
    "    return pred_resampled, resp_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE - Synthetic Minority Oversampling Technique\n",
    "Another method of oversampling to address target class imbalance in the dataset. Generates synthetic data points of the minority class by interpolating between the minority class instances using k nearest neighbors.\n",
    "\n",
    "__Note:__ This increases the size of the dataset and therefore the classifier will require more computational resources/time. Over sampling was not found to significantly improve performance during testing and SMOTE is not currently implemented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_resample(predictor_df, response_df, seed):\n",
    "    \"\"\"\n",
    "    Oversamples the dataset using the Synthetic Minority Oversampling Technique to correct target class imbalance. Returns the resampled predictors and responses as separate dataframes.\n",
    "    predictor_df - dataframe of features used as predictors.\n",
    "    target_df - dataframe of the target feature (e.g. F40).\n",
    "    \"\"\"\n",
    "\n",
    "    sm = SMOTE(sampling_strategy='auto', random_state=seed, k_neighbors=5)\n",
    "    pred_resampled, resp_resampled = sm.fit_resample(predictor_df, response_df)\n",
    "    return pred_resampled, resp_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a directory to output modeling results\n",
    "Names the output directory using the datetime that the script was run. \n",
    "Returns the name of the directory. The returned directory is used to output the trained model and/or results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir(base_dir):\n",
    "        \"\"\"\n",
    "        Create a directory named using the current datetime and returns the path to that directory.\n",
    "        Input: base_dir - path to the directory where the new directory will be created. \n",
    "        \"\"\"\n",
    "\n",
    "        datetime = dt.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        output_dir = os.path.join(base_dir, \"model_results_\" + datetime)\n",
    "\n",
    "        os.makedirs(output_dir)\n",
    "        return output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing \n",
    "Used to prepare the dataset for model development. The user must specify the path to the geodatabase and name of the point layer in that geodatabase to be processed.\n",
    "\n",
    "The function expects a point layer with a minimum of the following features: [FVT, FDST, FVC, FVH, F40]\n",
    "\n",
    "Note that we found that the best performing set of predictors was ['FVT', 'FVC', 'FVH', 'FDST', 'ZONE', 'BPS_FRG_NEW'] and the engineered features did not provide value in improving modeling results. The only modifications needed for the above set of predictors is to filter out the NULL values (-9999\\-1111) and the non-burnable F40 classes. \n",
    "\n",
    "__Steps:__\n",
    "1. Drops unneeded columns\n",
    "2. Creates EVT_* (e.g. EVT_CLASS) features by mapping FVT to each EVT hierarchy. \n",
    "3. Reclasses FDST by grouping by disturbance type\n",
    "4. Splits FVC/FVH into 4 separate columns: Tree/Forest, Shrub, Herb, Other. This is done to reduce dimensionality of the predictors.\n",
    "5. Creates a feature that aggregates F40 classes into their \"parent class\" - (i.e. \"Grass-Shrub\").\n",
    "6. Removes rows with -9999/-1111 in any field -- these are Null values.\n",
    "7. Removes Non-Burnable classes from the dataset using NB F40 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(gdb_path, gdb_layer):\n",
    "    \"\"\"\n",
    "    Reads in layer of sample points from specified geodatabase and prepares the data for the model.\n",
    "    gdb_path - Path to the geodatabase containing the data.\n",
    "    gdb_layer - name of the point layer in the geodatabase. \n",
    "    \"\"\"\n",
    "    # Read in gdf\n",
    "    sample_points = gpd.read_file(gdb_path, layer=gdb_layer)\n",
    "\n",
    "\n",
    "    # Drop unneeeded columns if present\n",
    "    sample_points = sample_points.drop(['Classified', 'GrndTruth', 'NEAR_FID', 'NEAR_DIST'], axis=1,\n",
    "                                       errors='ignore')\n",
    "\n",
    "\n",
    "    # Add in EVT columns based on FVT \n",
    "    ## Read in EVT data\n",
    "    EVT_df_path = r\"\\\\pnl\\projects\\BPAWildfire\\data\\Landfire\\F40_Modeling\\model_development\\LC22_EVT_230_bpa.csv\"\n",
    "    EVT_df = pd.read_csv(EVT_df_path)\n",
    "    EVT_df.head()\n",
    "\n",
    "    ## Create dictionaries to map FVT to EVT Hierarchies\n",
    "    EVT_ORDER_dict = dict(zip(EVT_df['EVT_FUEL'], EVT_df['EVT_ORDER']))\n",
    "    EVT_CLASS_dict = dict(zip(EVT_df['EVT_FUEL'], EVT_df['EVT_CLASS']))\n",
    "    EVT_PHYS_dict = dict(zip(EVT_df['EVT_FUEL'], EVT_df['EVT_PHYS']))\n",
    "    EVT_SBCLS_dict = dict(zip(EVT_df['EVT_FUEL'], EVT_df['EVT_SBCLS']))\n",
    "\n",
    "    ## Create EVT_* columns\n",
    "    sample_points['EVT_ORDER'] = sample_points['FVT'].map(EVT_ORDER_dict)\n",
    "    sample_points['EVT_CLASS'] = sample_points['FVT'].map(EVT_CLASS_dict)\n",
    "    sample_points['EVT_PHYS'] = sample_points['FVT'].map(EVT_PHYS_dict)\n",
    "    sample_points['EVT_SBLCS'] = sample_points['FVT'].map(EVT_SBCLS_dict)\n",
    "\n",
    "\n",
    "    # Reclass FDST to group by disturbance type\n",
    "    fdst_reclass_dict = {\n",
    "        range(111, 134) : 1,  # Fire\n",
    "        range(211, 234) : 2,  # Mechanical Add\n",
    "        range(311, 334) : 3,  # Mechanical Remove\n",
    "        range(411, 434) : 4,  # Windthrow\n",
    "        range(511, 534) : 5,  # Insects - Disease\n",
    "        range(611, 634) : 6,  # Mechanical Unknown\n",
    "        range(711, 734) : 7   # Mastication\n",
    "    }\n",
    "    sample_points['FDST_RECLASS'] = sample_points['FDST'].apply(lambda x: next((v for k, v in fdst_reclass_dict.items() if x in k), x))\n",
    "\n",
    "\n",
    "    # Split FVC into four features\n",
    "    ## 0 is fill value\n",
    "\n",
    "    ## Reclass to FVC_tree\n",
    "    fvc_tree_dict = {\n",
    "    range(11, 101) : 0,\n",
    "    range(111, 173) : 0\n",
    "    }\n",
    "    sample_points['FVC_TREE'] = sample_points['FVC'].apply(lambda x: next((v for k, v in fvc_tree_dict.items() if x in k), x))\n",
    "\n",
    "    ## Reclass to FVC_shrub\n",
    "    fvc_shrub_dict = {\n",
    "    range(11, 110) : 0,\n",
    "    range(121, 173) : 0\n",
    "    }\n",
    "    sample_points['FVC_SHRUB'] = sample_points['FVC'].apply(lambda x: next((v for k, v in fvc_shrub_dict.items() if x in k), x))\n",
    "\n",
    "    ## Reclass to FVC_herb\n",
    "    fvc_herb_dict = {\n",
    "    range(11, 120) : 0,\n",
    "    range(150, 173) : 0\n",
    "    }\n",
    "    sample_points['FVC_HERB'] = sample_points['FVC'].apply(lambda x: next((v for k, v in fvc_herb_dict.items() if x in k), x))\n",
    "\n",
    "    ## Reclass to FVC_other\n",
    "    ## 0:Fill, 1:Non-burnable Other, 2:Burnable Other, 3:Sparse Vegetation\n",
    "    fvc_other_dict = {\n",
    "    range(11, 13) : 1,\n",
    "    range(13, 18) : 2,\n",
    "    range(18, 96) : 1,\n",
    "    range(100, 101) : 3,\n",
    "    range(101, 130): 0,\n",
    "    range(150, 151) : 3,\n",
    "    range(151, 173) : 0\n",
    "    }\n",
    "    sample_points['FVC_OTHER'] = sample_points['FVC'].apply(lambda x: next((v for k, v in fvc_other_dict.items() if x in k), x))\n",
    "\n",
    "\n",
    "    # Split FVH into four features\n",
    "    ## 0 is fill value\n",
    "\n",
    "    ## Reclass to FVH_tree\n",
    "    fvh_tree_dict = {\n",
    "    range(11, 531) : 0\n",
    "    }\n",
    "    sample_points['FVH_TREE'] = sample_points['FVH'].apply(lambda x: next((v for k, v in fvh_tree_dict.items() if x in k), x))\n",
    "\n",
    "    ## Reclass to FVH_shrub\n",
    "    fvh_shrub_dict = {\n",
    "    range(11, 500) : 0,\n",
    "    range(603, 652) : 0\n",
    "    }\n",
    "    sample_points['FVH_SHRUB'] = sample_points['FVH'].apply(lambda x: next((v for k, v in fvh_shrub_dict.items() if x in k), x))\n",
    "\n",
    "    ## Reclass to FVH_herb\n",
    "    fvh_herb_dict = {\n",
    "    range(11, 101) : 0,\n",
    "    range(502, 651) : 0\n",
    "    }\n",
    "    sample_points['FVH_HERB'] = sample_points['FVH'].apply(lambda x: next((v for k, v in fvh_herb_dict.items() if x in k), x))\n",
    "\n",
    "    ## Reclass to FVH_other\n",
    "    ## 0:Fill, 1:Non-burnable Other, 2:Burnable Other, 3:Sparse Vegetation\n",
    "    fvh_other_dict = {\n",
    "    range(11, 13) : 1,\n",
    "    range(13, 18) : 2,\n",
    "    range(18, 96) : 1,\n",
    "    range(100, 101) : 3,\n",
    "    range(101, 130): 0,\n",
    "    range(425, 652) : 0\n",
    "    }\n",
    "    sample_points['FVH_OTHER'] = sample_points['FVH'].apply(lambda x: next((v for k, v in fvh_other_dict.items() if x in k), x))\n",
    "\n",
    "    \n",
    "    # Create feature of grouped F40\n",
    "    ## Create dictionary to aggregate F40 models into groups\n",
    "    F40_groups = {\n",
    "        range(91, 100):'NonBurnable',\n",
    "        range(101,110):'Grass',\n",
    "        range(121,125):'Grass-Shrub',\n",
    "        range(141,150):'Shrub',\n",
    "        range(161,166):'Timber-Understory',\n",
    "        range(181,190):'Timber Litter',\n",
    "        range(201,204):'Slash-Blowdown'\n",
    "    }\n",
    "\n",
    "    ## Create column to aggregate F40 models into groups\n",
    "    sample_points['F40_GROUP'] = sample_points['F40'].apply(lambda x: next((v for k, v in F40_groups.items() if x in k), x))\n",
    "\n",
    "\n",
    "    # Remove -9999/-1111\n",
    "    matches = sample_points[(sample_points.isin([-1111, -9999])).any(axis=1)]  # Find rows with -1111/-9999 in any column\n",
    "    sample_points = sample_points.drop(matches.index, axis=0)  # Drop those rows\n",
    "\n",
    "\n",
    "    # Remove Non-Burnable Classes\n",
    "    F40_NB = [91, 92, 93, 98, 99]  # Nonburnable F40 Classes\n",
    "    sample_points = sample_points.loc[~sample_points['F40'].isin(F40_NB)]  # Drop NB classes\n",
    "\n",
    "\n",
    "    # Drop columns that are not predictors\n",
    "    #sample_points = sample_points.drop(['FVC', 'FVH', 'FDST', 'EVT_ORDER'], axis=1)  \n",
    "    \n",
    "    return sample_points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate RF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForestClassifier(n_est=100, min_samples_leaf=50, bootstrap=True, oob_score=True, \n",
    "                           n_jobs=-1, random_state=1234, max_features='auto', class_weight=None):\n",
    "    \"\"\"\n",
    "    Instantiate a sklearn.ensemble.RandomForestClassifier.\n",
    "    \"\"\"\n",
    "    rf_classifier = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        bootstrap=bootstrap,\n",
    "        oob_score=oob_score,\n",
    "        n_jobs=n_jobs,\n",
    "        random_state=random_state,\n",
    "        max_features=max_features,\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "\n",
    "    return rf_classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram-Based Gradient Boosting Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate HGBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histGradientBoostingClassifier(categorical_feature_list, class_weight=None):\n",
    "    \"\"\"\n",
    "    Instantiate a sklearn.ensemble.HistGradientBoostingClassifier.\n",
    "    Takes a list of categorical features to be encoded using native function. \n",
    "    \"\"\"\n",
    "\n",
    "    hgb_classifier = HistGradientBoostingClassifier(\n",
    "        categorical_features=categorical_feature_list,  # Natively handle categorical variables\n",
    "        class_weight=class_weight\n",
    "        \n",
    "    )\n",
    "\n",
    "    return hgb_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "Trains and returns a model given a dataset to train on and model specifications. Model specifications incldue:\n",
    "- Model_type: Random Forest or Histogram-based Boosting Classifier\n",
    "- Class_weight: Which method to use to correct class imbalance. \"balanced\" will specify that the classifier assign higher weights to minority classes. \"oversampled\" will apply random oversampling to the data to increase the representation of minority classes in the dataset. \n",
    "- Seed: Specifies the random state to ensure reproducibility\n",
    "- Run: A subset of predictors specified using a reference csv.\n",
    "- F40_GROUP: Specify whether to append the F40_GROUP feature to the set of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, model_type, class_weight, seed, run, F40_GROUP=False):\n",
    "    \"\"\"\n",
    "    Trains specified model. \n",
    "    model_type = \"RF\" / \"HGBC\"\n",
    "    class_weight = \"balanced\" / \"oversampled\" / \"none\"\n",
    "    run = list of predictors from reference csv.\n",
    "    Returns model and test dataset.\n",
    "    \"\"\"\n",
    "    target = \"F40\"\n",
    "\n",
    "    # Encode the data if running a Random Forest Model\n",
    "    if model_type == \"RF\":\n",
    "        train_data = targetEncoder(train_data, target)\n",
    "    \n",
    "\n",
    "    # Get list of predictors for run\n",
    "    predictors = run.loc[run == 1].index.tolist()  \n",
    "    predictors = [x for x in predictors if x not in ['F40', 'Run']]  # Drops \"Runs\" and \"F40\" \n",
    "    print(predictors)\n",
    "\n",
    "    # Append F40_GROUP if true\n",
    "    if F40_GROUP == True:\n",
    "        predictors.append('F40_GROUP')\n",
    "    \n",
    "\n",
    "    # If Random Forest - get list of encoded predictors\n",
    "    # If HGBC - get list of categorical variables to be encoded\n",
    "    if model_type == \"RF\":\n",
    "        predictors = [j for i in predictors for j in train_data.columns.tolist() if i in j]\n",
    "    elif model_type == \"HGBC\":\n",
    "        cat_variables = get_cat_features(predictors)\n",
    "\n",
    "\n",
    "    # Separate training data\n",
    "    y_train = train_data[target].copy()\n",
    "    x_train = train_data[predictors].copy()\n",
    "\n",
    "\n",
    "    # Oversample the training data if true\n",
    "    if class_weight == \"oversampled\":\n",
    "        x_train, y_train = overSampler(x_train, y_train, seed)\n",
    "        class_weight = None  # For instantiating the classifier\n",
    "\n",
    "\n",
    "    # Fit specified classifier with training data\n",
    "    if model_type == \"RF\":\n",
    "        model = randomForestClassifier(n_est=100, min_samples_leaf=50, bootstrap=True, oob_score=True,\n",
    "                                            n_jobs=-1, random_state=seed, max_features='sqrt', class_weight=class_weight)\n",
    "    elif model_type == \"HGBC\":\n",
    "        model = histGradientBoostingClassifier(cat_variables, class_weight=class_weight)  # Use default parameters for now\n",
    "    \n",
    "\n",
    "    # Fit the model with the training data\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Return the fit model\n",
    "    return model         \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using trained model\n",
    "Return F40 class predictions and evaluation metrics given a trained model and a test dataset. \n",
    "- model - a trained sklearn model produced using train_model() above.  \n",
    "- model_type: Random Forest or Histogram-based Boosting Classifier.\n",
    "- test_data: Test dataset that includes target labels.\n",
    "- run_index: The index of the run (i.e. set of predictors) used to train the model.\n",
    "- run: A subset of predictors specified using a reference csv.\n",
    "- F40_GROUP: Specify whether to append the F40_GROUP feature to the set of predictors.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_F40(model, model_type, test_data, run_index, run, F40_GROUP=False):\n",
    "    \"\"\"\n",
    "    Predicts F40 class of test data given a trained model.\n",
    "    model_type = 'RF' / 'HGBC'\n",
    "    run_index = integer corresponding to index of run in reference csv.\n",
    "    run = set of predictors from reference csv. \n",
    "    returns dict with \n",
    "        'metrics' : A set of metrics to evaluate performance\n",
    "        'predictions' : A dataframe of the test_dataset predictors with both predictions and actual labels attached. \n",
    "    \"\"\"\n",
    "    # Create results file \n",
    "    results = pd.DataFrame(columns=['Run', 'Accuracy', 'Balanced_Accuracy', 'Precision', 'Recall', 'F1_score', 'Predictors'])    \n",
    "\n",
    "    target = \"F40\"\n",
    "\n",
    "    # Encode the data if running a Random Forest Model\n",
    "    if model_type == \"RF\":\n",
    "        test_data = targetEncoder(test_data, target)\n",
    "\n",
    "     # Get list of predictors for run\n",
    "    predictors = run.loc[run == 1].index.tolist()  \n",
    "    predictors = [x for x in predictors if x not in ['F40', 'Run']] # Drops \"Runs\" and \"F40\"\n",
    "    \n",
    "    \n",
    "    # Append F40_GROUP\n",
    "    if F40_GROUP == True:\n",
    "        predictors.append('F40_GROUP')\n",
    "\n",
    "    # If Random forest, get list of encoded predictors\n",
    "    if model_type == \"RF\":\n",
    "        predictors = [j for i in predictors for j in test_data.columns.tolist() if i in j]\n",
    "\n",
    "    # Separate the predictors if using test data\n",
    "    y_test = test_data[target].copy()\n",
    "    x_test = test_data[predictors].copy()\n",
    "\n",
    "    # Perform prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Get metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Append metrics to results dataframe\n",
    "    results.loc[len(results)] = [run_index, accuracy, bal_acc, precision, recall, f1, x_test.columns.tolist()]\n",
    "\n",
    "    # Create dataframe with test data, original F40, and predicted F40\n",
    "    model_df = pd.concat([x_test, y_test], axis=1)\n",
    "    model_df[\"F40-predicted\"] = y_pred\n",
    "\n",
    "    # Return metrics and model results\n",
    "    return {'metrics':results,\n",
    "            'predictions':model_df}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model Iterations\n",
    "Allows a single function to iterate through different models/parameters in order to identify what provides the best performance. \n",
    "Currently specified to loop through both RF and HGBC models with different methods to address class imbalance and whether to include F40_GROUP as a predictor. Each \"iteration\" will run each set of predictors in the reference csv provided through runs_path and create a file named with the model specification and containing metrics for each run (i.e. set of predictors) for that iteration.\n",
    "\n",
    "These files can then be used to evaluate model performance in terms of which predictors and which model types/parameters provide the best performance.\n",
    "\n",
    "__Note:__ This function can be very time intensive - especially if oversampling is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iterations(sample_points, runs_path, seed, models, weights, F40_GROUPS):    \n",
    "    \"\"\"\n",
    "    Runs various iterations of models using supplied runs (i.e. sets of predictors and parameters)\n",
    "    models = list of models - options 'HGBC' / 'RF'ArithmeticError\n",
    "    weights = list of methods to try to correct class imbalance - options: 'balanced', None, 'oversampled'\n",
    "    F40_GROUPS = whether to include F40_GROUP as predictor as list - i.e. [False, True], [True], or [False]\n",
    "    \"\"\"\n",
    "\n",
    "    # Get run iterations\n",
    "    runs = pd.read_csv(runs_path)\n",
    "\n",
    "    # Make directory to output results to\n",
    "    base_dir = r\"\\\\pnl\\projects\\BPAWildfire\\data\\Landfire\\fuels_modeling\\F40_modeling\\model_outputs\\tabular\"\n",
    "    output_dir = make_dir(base_dir)\n",
    "    output_file = os.path.join(output_dir, \"model_results.csv\")\n",
    "\n",
    "    # Define constants\n",
    "    train_frac = 0.8\n",
    "    test_frac = 0.2\n",
    "    target=\"F40\"\n",
    "\n",
    "    # Perform train/test split\n",
    "    train, test = train_test_split(sample_points, train_size=train_frac, test_size=test_frac,\n",
    "                                random_state=seed, shuffle=True, stratify=sample_points[target])\n",
    "\n",
    "    for weight in weights:\n",
    "        for model_type in models:\n",
    "            for GROUP in F40_GROUPS: \n",
    "                results = pd.DataFrame(columns=['Run', 'Accuracy', 'Balanced_Accuracy', 'Precision', 'Recall', 'F1_score', 'Predictors'])\n",
    "                output_file = os.path.join(output_dir,f\"results_{model_type}_F40_{GROUP}_Weight_{weight}.csv\")\n",
    "                for i in range(len(runs)):\n",
    "                    # Track which run is processing\n",
    "                    clear_output(wait=True)\n",
    "                    print(f\"{weight}, {model_type}, {GROUP}, Run {i+1} of {len(runs)}\")\n",
    "\n",
    "                    model = train_model(train_data=train, model_type=model_type, class_weight=weight, seed=1234, run=runs.iloc[i],\n",
    "                                        F40_GROUP=GROUP)\n",
    "                    model_results = predict_F40(model=model, model_type=model_type, test_data=test, run_index=i, run=runs.iloc[i],\n",
    "                                                F40_GROUP=GROUP)\n",
    "                    results.loc[len(results)] = model_results['metrics'].iloc[0]\n",
    "                results.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Load in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['F40', 'FDST', 'FVC', 'FVH', 'ZONE', 'PYROME', 'ECOREGION', 'FVT',\n",
       "       'BPS_GROUPVEG', 'BPS_FRG_NEW', 'ASPECT', 'ELEVATION', 'SLOPE', 'BPS',\n",
       "       'geometry', 'EVT_ORDER', 'EVT_CLASS', 'EVT_PHYS', 'EVT_SBLCS',\n",
       "       'FDST_RECLASS', 'FVC_TREE', 'FVC_SHRUB', 'FVC_HERB', 'FVC_OTHER',\n",
       "       'FVH_TREE', 'FVH_SHRUB', 'FVH_HERB', 'FVH_OTHER', 'F40_GROUP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 1234\n",
    "\n",
    "# Read in data\n",
    "## Specify paths to geodatabase and layer from geodatabas\n",
    "\n",
    "## Path to geodatabase\n",
    "gdb_path_pnnl = paths_dict['LF23_gdb']\n",
    "\n",
    "## GDB layer\n",
    "gdb_layer = paths_dict['LF23_sample_points_fpath']\n",
    "\n",
    "## Read in and process data from GDB\n",
    "sample_points = data_prep(gdb_path_pnnl, gdb_layer)\n",
    "\n",
    "# Runs reference csv path - each set of predictors specified here will be run\n",
    "runs_path = paths_dict['runs_fpath']\n",
    "\n",
    "sample_points.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model Iterations\n",
    "Runs all set sets of predictors specified in the runs_path csv. Used to identify best set of parameters and predictors.\n",
    "Parameters in question are model_type, imbalance correction method, and whether to include F40_GROUP. Creates a directory and outputs csv files with the results for each combination to that directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None, RF, True, Run 14 of 14\n",
      "['FVC', 'FVH', 'BPS_GROUPVEG', 'ASPECT', 'ELEVATION', 'SLOPE']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mcco573\\AppData\\Local\\miniconda3\\envs\\geospatial_310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Run model iterations to identify best set of predictors/parameters\n",
    "run_iterations(sample_points=sample_points, runs_path=runs_path, seed=1234,\n",
    "               models = ['HGBC', 'RF'], weights=['balanced', None, 'oversampled'], F40_GROUPS=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Save Model \n",
    "Train and save the model that has been found to perform the best.\n",
    "- Model: Histogram-based Gradient Boosting Classifier with class-weight='balanced'\n",
    "- Predictors: ['FVT', 'FVC', 'FVH', 'FDST', 'ZONE', 'BPS_FRG_NEW']\n",
    "\n",
    "Note that including F40_GROUP improves performance but we are unsure if this is valid.\n",
    "\n",
    "__NOTE__: This is currently set to train on _ALL_ of the sample points with the idea that the model will be applied to the full BPA service territory raster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FVT', 'FVC', 'FVH', 'FDST', 'ZONE', 'BPS_FRG_NEW']\n",
      "Saved to: C:\\Users\\mcco573\\OneDrive - PNNL\\Documents\\_Projects\\BPA Wildfire\\F40 Random Forest Model\\models\\models_3-18-24\\HGBC_Preds_run-15_GROUP-False_weight-balanced_2024-03-18_12-29-34.joblib\n"
     ]
    }
   ],
   "source": [
    "# Get run iterations - will train using run 15\n",
    "runs = pd.read_csv(runs_path) \n",
    "\n",
    "# Define Parameters\n",
    "model_type=\"HGBC\"\n",
    "GROUP = False\n",
    "weight = \"balanced\"\n",
    "i = 15  # run_index\n",
    "\n",
    "# Train Model\n",
    "model = train_model(train_data=sample_points, model_type=model_type, class_weight=weight, seed=1234, run=runs.iloc[i],\n",
    "                    F40_GROUP=GROUP)\n",
    "model\n",
    "\n",
    "# Save the model out\n",
    "out_dir = paths_dict['models_out_dir']\n",
    "out_file = os.path.join(out_dir, f\"{model_type}_Preds_run-{i}_GROUP-{GROUP}_weight-{weight}_{dt.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.joblib\")\n",
    "\n",
    "dump(model, out_file)\n",
    "print(f\"Saved to: {out_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run single model and return predictions\n",
    "Run a specified model and get the prediction results and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m179\u001b[39m  \u001b[38;5;66;03m# run_index\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Train Model\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m model \u001b[38;5;241m=\u001b[39m train_model(train_data\u001b[38;5;241m=\u001b[39mtrain, model_type\u001b[38;5;241m=\u001b[39mmodel_type, class_weight\u001b[38;5;241m=\u001b[39mweight, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1234\u001b[39m, run\u001b[38;5;241m=\u001b[39m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[0;32m     21\u001b[0m                     F40_GROUP\u001b[38;5;241m=\u001b[39mGROUP)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Use model to predict on test data\u001b[39;00m\n\u001b[0;32m     24\u001b[0m model_results \u001b[38;5;241m=\u001b[39m predict_F40(model\u001b[38;5;241m=\u001b[39mmodel, model_type\u001b[38;5;241m=\u001b[39mmodel_type, test_data\u001b[38;5;241m=\u001b[39mtest, run_index\u001b[38;5;241m=\u001b[39mi, run\u001b[38;5;241m=\u001b[39mruns\u001b[38;5;241m.\u001b[39miloc[i],\n\u001b[0;32m     25\u001b[0m                             F40_GROUP\u001b[38;5;241m=\u001b[39mGROUP)\n",
      "File \u001b[1;32mc:\\Users\\mcco573\\AppData\\Local\\miniconda3\\envs\\geospatial_310\\lib\\site-packages\\pandas\\core\\indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mcco573\\AppData\\Local\\miniconda3\\envs\\geospatial_310\\lib\\site-packages\\pandas\\core\\indexing.py:1714\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1711\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1713\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m-> 1714\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\mcco573\\AppData\\Local\\miniconda3\\envs\\geospatial_310\\lib\\site-packages\\pandas\\core\\indexing.py:1647\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1645\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# Get run iterations\n",
    "runs = pd.read_csv(runs_path)    \n",
    "\n",
    "# Define constants\n",
    "train_frac = 0.8\n",
    "test_frac = 0.2\n",
    "target=\"F40\"\n",
    "\n",
    "# Perform train/test split\n",
    "train, test = train_test_split(sample_points, train_size=train_frac, test_size=test_frac,\n",
    "                            random_state=seed, shuffle=True, stratify=sample_points[target])\n",
    "\n",
    "# Define Parameters\n",
    "model_type=\"HGBC\"\n",
    "GROUP = False\n",
    "weight = \"balanced\"\n",
    "i = 15  # run_index\n",
    "\n",
    "# Train Model\n",
    "model = train_model(train_data=train, model_type=model_type, class_weight=weight, seed=1234, run=runs.iloc[i],\n",
    "                    F40_GROUP=GROUP)\n",
    "\n",
    "# Use model to predict on test data\n",
    "model_results = predict_F40(model=model, model_type=model_type, test_data=test, run_index=i, run=runs.iloc[i],\n",
    "                            F40_GROUP=GROUP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FVC_TREE</th>\n",
       "      <th>FVC_SHRUB</th>\n",
       "      <th>FVC_HERB</th>\n",
       "      <th>FVC_OTHER</th>\n",
       "      <th>FVH_TREE</th>\n",
       "      <th>FVH_SHRUB</th>\n",
       "      <th>FVH_HERB</th>\n",
       "      <th>FVH_OTHER</th>\n",
       "      <th>PYROME</th>\n",
       "      <th>EVT_SBLCS</th>\n",
       "      <th>BPS_FRG_NEW</th>\n",
       "      <th>ASPECT</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>SLOPE</th>\n",
       "      <th>F40_GROUP</th>\n",
       "      <th>F40</th>\n",
       "      <th>F40-predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88987</th>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>159</td>\n",
       "      <td>1304</td>\n",
       "      <td>9</td>\n",
       "      <td>Timber Litter</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29427</th>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>507</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Mixed evergreen-deciduous shrubland</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>1909</td>\n",
       "      <td>2</td>\n",
       "      <td>Grass-Shrub</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37797</th>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Evergreen shrubland</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>1316</td>\n",
       "      <td>0</td>\n",
       "      <td>Shrub</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74236</th>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Evergreen closed tree canopy</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>1393</td>\n",
       "      <td>30</td>\n",
       "      <td>Shrub</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22174</th>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>607</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Evergreen open tree canopy</td>\n",
       "      <td>2</td>\n",
       "      <td>271</td>\n",
       "      <td>1708</td>\n",
       "      <td>37</td>\n",
       "      <td>Grass-Shrub</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       FVC_TREE  FVC_SHRUB  FVC_HERB  FVC_OTHER  FVH_TREE  FVH_SHRUB  \\\n",
       "88987       104          0         0          0       619          0   \n",
       "29427         0        113         0          0         0        507   \n",
       "37797         0        112         0          0         0        520   \n",
       "74236       106          0         0          0       619          0   \n",
       "22174       102          0         0          0       607          0   \n",
       "\n",
       "       FVH_HERB  FVH_OTHER  PYROME                            EVT_SBLCS  \\\n",
       "88987         0          0     7.0                                  NaN   \n",
       "29427         0          0    13.0  Mixed evergreen-deciduous shrubland   \n",
       "37797         0          0    19.0                  Evergreen shrubland   \n",
       "74236         0          0     9.0         Evergreen closed tree canopy   \n",
       "22174         0          0    20.0           Evergreen open tree canopy   \n",
       "\n",
       "       BPS_FRG_NEW  ASPECT  ELEVATION  SLOPE      F40_GROUP  F40  \\\n",
       "88987            7     159       1304      9  Timber Litter  188   \n",
       "29427            8      -1       1909      2    Grass-Shrub  122   \n",
       "37797            8      -1       1316      0          Shrub  142   \n",
       "74236            2      58       1393     30          Shrub  142   \n",
       "22174            2     271       1708     37    Grass-Shrub  122   \n",
       "\n",
       "       F40-predicted  \n",
       "88987            188  \n",
       "29427            122  \n",
       "37797            142  \n",
       "74236            142  \n",
       "22174            122  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the predictions for analysis\n",
    "output_dir = paths_dict['model_output_dir']\n",
    "output_file = f\"{model_type}_Preds_run-{i}_GROUP-{GROUP}_weight-{weight}.csv\"\n",
    "\n",
    "# Write and check the predictions\n",
    "#model_results['predictions'].to_csv(os.path.join(output_dir, output_file))\n",
    "model_results['predictions'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced_Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>Predictors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>179</td>\n",
       "      <td>0.844907</td>\n",
       "      <td>0.553852</td>\n",
       "      <td>0.861451</td>\n",
       "      <td>0.844907</td>\n",
       "      <td>0.849339</td>\n",
       "      <td>[FVC_TREE, FVC_SHRUB, FVC_HERB, FVC_OTHER, FVH...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Run  Accuracy  Balanced_Accuracy  Precision    Recall  F1_score  \\\n",
       "0  179  0.844907           0.553852   0.861451  0.844907  0.849339   \n",
       "\n",
       "                                          Predictors  \n",
       "0  [FVC_TREE, FVC_SHRUB, FVC_HERB, FVC_OTHER, FVH...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the model results\n",
    "model_results['metrics']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model using LF22 and LF23 data\n",
    "Evaluate model performance using LF22 data as the training dataset and LF23 data as the test (and vice versa). The goal is to evaluate the validity of the model applied between years - which is the ultimate goal. \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "\n",
    "# Read in data\n",
    "## Specify paths to geodatabase and layer from geodatabase\n",
    "\n",
    "## Path to geodatabase\n",
    "gdb_path_pnnl = paths_dict['LF23_gdb']\n",
    "## GDB layers\n",
    "LF22_gdb_layer = paths_dict['LF22_sample_points_fpath']\n",
    "LF23_gdb_layer = paths_dict['LF23_sample_points_fpath']\n",
    "\n",
    "## Read in and process data from GDB\n",
    "LF22_sample_points = data_prep(gdb_path_pnnl, LF22_gdb_layer)\n",
    "LF23_sample_points = data_prep(gdb_path_pnnl, LF23_gdb_layer)\n",
    "\n",
    "# Reference csv of runs\n",
    "runs_path = paths_dict['runs_fpath']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on LF22 and Predict on LF23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FVT', 'FVC', 'FVH', 'FDST', 'ZONE', 'BPS_FRG_NEW']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mcco573\\AppData\\Local\\miniconda3\\envs\\geospatial_310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Read in data\n",
    "## Get run iterations\n",
    "runs = pd.read_csv(runs_path)    \n",
    "\n",
    "## Read in train/test sets\n",
    "train = LF22_sample_points\n",
    "test = LF23_sample_points\n",
    "\n",
    "# Define constants\n",
    "train_frac = 0.8\n",
    "test_frac = 0.2\n",
    "target=\"F40\"\n",
    "\n",
    "# Define Parameters\n",
    "model_type=\"HGBC\"\n",
    "GROUP = True\n",
    "weight = \"balanced\"\n",
    "i = 15  # run_index\n",
    "\n",
    "# Train Model\n",
    "model = train_model(train_data=train, model_type=model_type, class_weight=weight, seed=1234, run=runs.iloc[i],\n",
    "                    F40_GROUP=GROUP)\n",
    "\n",
    "# Use model to predict on test data\n",
    "model_results = predict_F40(model=model, model_type=model_type, test_data=test, run_index=i, run=runs.iloc[i],\n",
    "                            F40_GROUP=GROUP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced_Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>Predictors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0.960472</td>\n",
       "      <td>0.906817</td>\n",
       "      <td>0.969159</td>\n",
       "      <td>0.960472</td>\n",
       "      <td>0.962203</td>\n",
       "      <td>[FVT, FVC, FVH, FDST, ZONE, BPS_FRG_NEW, F40_G...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Run  Accuracy  Balanced_Accuracy  Precision    Recall  F1_score  \\\n",
       "0   15  0.960472           0.906817   0.969159  0.960472  0.962203   \n",
       "\n",
       "                                          Predictors  \n",
       "0  [FVT, FVC, FVH, FDST, ZONE, BPS_FRG_NEW, F40_G...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optionally write out model predictions\n",
    "output_dir = paths_dict['model_output_dir']\n",
    "output_file = f\"Train-LF22_Predict-LF23_{model_type}_Preds_run-{i}_GROUP-{GROUP}_weight-{weight}.csv\"\n",
    "\n",
    "#model_results['predictions'].to_csv(os.path.join(output_dir, output_file))\n",
    "\n",
    "# Show Results\n",
    "model_results['metrics']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on LF23 and Predict on LF22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m179\u001b[39m  \u001b[38;5;66;03m# run_index\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Train Model\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m model \u001b[38;5;241m=\u001b[39m train_model(train_data\u001b[38;5;241m=\u001b[39mtrain, model_type\u001b[38;5;241m=\u001b[39mmodel_type, class_weight\u001b[38;5;241m=\u001b[39mweight, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1234\u001b[39m, run\u001b[38;5;241m=\u001b[39m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[0;32m     22\u001b[0m                     F40_GROUP\u001b[38;5;241m=\u001b[39mGROUP)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Use model to predict on test data\u001b[39;00m\n\u001b[0;32m     25\u001b[0m model_results \u001b[38;5;241m=\u001b[39m predict_F40(model\u001b[38;5;241m=\u001b[39mmodel, model_type\u001b[38;5;241m=\u001b[39mmodel_type, test_data\u001b[38;5;241m=\u001b[39mtest, run_index\u001b[38;5;241m=\u001b[39mi, run\u001b[38;5;241m=\u001b[39mruns\u001b[38;5;241m.\u001b[39miloc[i],\n\u001b[0;32m     26\u001b[0m                             F40_GROUP\u001b[38;5;241m=\u001b[39mGROUP)\n",
      "File \u001b[1;32mc:\\Users\\mcco573\\AppData\\Local\\miniconda3\\envs\\geospatial_310\\lib\\site-packages\\pandas\\core\\indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mcco573\\AppData\\Local\\miniconda3\\envs\\geospatial_310\\lib\\site-packages\\pandas\\core\\indexing.py:1714\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1711\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1713\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m-> 1714\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\mcco573\\AppData\\Local\\miniconda3\\envs\\geospatial_310\\lib\\site-packages\\pandas\\core\\indexing.py:1647\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1645\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# Get run iterations\n",
    "runs = pd.read_csv(runs_path)    \n",
    "\n",
    "# Define constants\n",
    "train_frac = 0.8\n",
    "test_frac = 0.2\n",
    "target=\"F40\"\n",
    "\n",
    "# Perform train/test split\n",
    "train = LF23_sample_points\n",
    "test = LF22_sample_points\n",
    "\n",
    "# Define Parameters\n",
    "model_type=\"HGBC\"\n",
    "GROUP = False\n",
    "weight = None\n",
    "i = 179  # run_index\n",
    "\n",
    "\n",
    "# Train Model\n",
    "model = train_model(train_data=train, model_type=model_type, class_weight=weight, seed=1234, run=runs.iloc[i],\n",
    "                    F40_GROUP=GROUP)\n",
    "\n",
    "# Use model to predict on test data\n",
    "model_results = predict_F40(model=model, model_type=model_type, test_data=test, run_index=i, run=runs.iloc[i],\n",
    "                            F40_GROUP=GROUP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced_Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>Predictors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>179</td>\n",
       "      <td>0.735776</td>\n",
       "      <td>0.502878</td>\n",
       "      <td>0.75063</td>\n",
       "      <td>0.735776</td>\n",
       "      <td>0.735398</td>\n",
       "      <td>[FVC_TREE, FVC_SHRUB, FVC_HERB, FVC_OTHER, FVH...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Run  Accuracy  Balanced_Accuracy  Precision    Recall  F1_score  \\\n",
       "0  179  0.735776           0.502878    0.75063  0.735776  0.735398   \n",
       "\n",
       "                                          Predictors  \n",
       "0  [FVC_TREE, FVC_SHRUB, FVC_HERB, FVC_OTHER, FVH...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optionally write out model predictions\n",
    "output_dir = paths_dict['model_output_dir']\n",
    "output_file = f\"Train-LF23_Predict-LF22_{model_type}_Preds_run-{i}_GROUP-{GROUP}_weight-{weight}.csv\"\n",
    "\n",
    "model_results['predictions'].to_csv(os.path.join(output_dir, output_file))\n",
    "\n",
    "# Show Results\n",
    "model_results['metrics']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
