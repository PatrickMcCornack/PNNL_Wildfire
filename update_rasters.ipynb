{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABOUT\n",
    "__Author__: Pat McCornack\n",
    "\n",
    "__Date__: 5/29/2024\n",
    "\n",
    "__Purpose:__ \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.windows import Window\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from joblib import load\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define filepaths\n",
    "local_root_dir = r\"C:\\Users\\mcco573\\OneDrive - PNNL\\Documents\\_Projects\\BPA Wildfire\\fuelscape_modeling\" \n",
    "pnnl_root_dir = r\"\\\\pnl\\projects\\BPAWildfire\\data\\Landfire\\fuels_modeling\\fuelscape_modeling\"\n",
    "\n",
    "# Choose whether to work from local or drive\n",
    "active_root_dir = pnnl_root_dir\n",
    "\n",
    "\n",
    "# Define the source raster file names\n",
    "data_dir =  os.path.join(active_root_dir, r'..\\LF_raster_data\\bpa_service_territory')\n",
    "ref_data_dir = os.path.join(data_dir, r\"..\\_tables\")\n",
    "raster_fpaths = {\n",
    "    \"LF20_F40\" : os.path.join(data_dir, \"LC22_F40_220_bpa.tif\"),\n",
    "    \"LF20_FVT\" : os.path.join(data_dir, \"LC22_FVT_220_bpa.tif\"),\n",
    "    \"LF22_FVT\" : os.path.join(data_dir, \"LC22_FVT_230_bpa.tif\"),\n",
    "    \"LF20_FVC\" : os.path.join(data_dir, \"LC22_FVC_220_bpa.tif\"),\n",
    "    \"LF22_FVC\" : os.path.join(data_dir, \"LC22_FVC_230_bpa.tif\"),\n",
    "    \"LF20_FVH\" : os.path.join(data_dir, \"LC22_FVH_220_bpa.tif\"),\n",
    "    \"LF22_FVH\" : os.path.join(data_dir, \"LC22_FVH_230_bpa.tif\"),\n",
    "    \"LF22_FDST\" : os.path.join(data_dir, \"LC22_FDst_230_bpa.tif\"),\n",
    "    \"BPS\" : os.path.join(data_dir, \"LC20_BPS_220_bpa.tif\"),\n",
    "    \"ZONE\" : os.path.join(data_dir, \"us_lf_zones_bpa.tif\"),\n",
    "    \"ASPECT\" : os.path.join(data_dir, \"LC20_Asp_220_bpa.tif\"),\n",
    "    \"SLOPE\" : os.path.join(data_dir, \"LC20_SlpD_220_bpa.tif\"),\n",
    "    \"ELEVATION\" : os.path.join(data_dir, \"LC20_Elev_220_bpa.tif\"),\n",
    "    \"BPS_FRG_NE\" : os.path.join(data_dir, \"BPS_FRG_NEW.tif\")\n",
    "\n",
    "}\n",
    "\n",
    "models_dir = os.path.join(active_root_dir, \"models\")\n",
    "models_fpath_dict = {\n",
    "    'LF22_F40' : os.path.join(models_dir, \"LF22_F40_model_2024-05-29_09-28-44\"),\n",
    "    'LF22_FVT' : os.path.join(models_dir, \"LF22_FVT_HGBC_model_2024-05-29_09-37-32\"),\n",
    "    'LF22_FVC' : os.path.join(models_dir, \"LF22_FVC_HGBC_model_2024-05-29_09-31-57\"),\n",
    "    'LF22_FVH' : os.path.join(models_dir, \"LF22_FVH_HGBC_model_2024-05-29_09-35-38\"),\n",
    "}\n",
    "\n",
    "out_chunk_dir = os.path.join(active_root_dir, r\"outputs\\geospatial\")\n",
    "out_raster_dir = os.path.join(data_dir, r'_predicted_rasters')\n",
    "out_fname_dict = {\n",
    "    'LF22_F40' : 'Pred_LF22_F40',\n",
    "    'LF22_FVT' : 'Pred_LF22_FVT',\n",
    "    'LF22_FVC' : 'Pred_LF22_FVC',\n",
    "    'LF22_FVH' : 'Pred_LF22_FVH'\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Directory\n",
    "Creates a directory where data will be output - labeled with the datetime that the script is run. Returns name of directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir(base_dir, file_name):\n",
    "        \"\"\"\n",
    "        Create a directory named using the current datetime.\n",
    "        Returns:\n",
    "        - Name of the directory as a string\n",
    "        \"\"\"\n",
    "\n",
    "        datetime = dt.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        output_dir = os.path.join(base_dir, file_name + '_' + datetime)\n",
    "\n",
    "        os.makedirs(output_dir)\n",
    "        return output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Feature Engineering__\n",
    "Use values from the rasters to create new features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Reference Data\n",
    "Use the LANDFIRE csv tables to create dictionaries to be used to map raster layer values to other features.\n",
    "1. Separate LF22_FDST into separate features for type, severity, and time since disturbance.\n",
    "2. Map the BPS value to BPS_NAME in order to reduce cardinality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ref_data(ref_data_dir=ref_data_dir):\n",
    "    \"\"\"\n",
    "    Creates dictionaries from LF attributes tables that are used to map layer values to other features. Returns a dictionary of dictionaries. \n",
    "    \"\"\"\n",
    "    data_dir = ref_data_dir\n",
    "    BPS_fname = \"LF20_BPS_220.csv\"\n",
    "\n",
    "    # Create empty dictionary\n",
    "    LF_ref_dicts = {}\n",
    "\n",
    "    # Get BPS reference dictionary\n",
    "    BPS_df = pd.read_csv(os.path.join(data_dir, BPS_fname))\n",
    "    LF_ref_dicts[\"BPS_NAME\"] = dict(BPS_df[['VALUE', 'BPS_NAME']].values)\n",
    "\n",
    "    return LF_ref_dicts                        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Features\n",
    "Use dictionaries created using read_ref_data to map raster values to new features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_features(df, feature_list = ['BPS_NAME']):\n",
    "    \"\"\"\n",
    "    Joins in additional features using LF attribute tables. \n",
    "    \"\"\"\n",
    "    \n",
    "    LF_ref_dicts = read_ref_data()\n",
    "    \n",
    "    source_layers = {\n",
    "        'BPS_NAME' : 'BPS', \n",
    "    }\n",
    "\n",
    "    for feature in feature_list:\n",
    "        df[feature] = df[source_layers[feature]].map(LF_ref_dicts[feature]).copy()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess window dataframe\n",
    "Prepares the data to be run through the model. Separates out null and non-burnable values. Returns a dictionary with: \n",
    "1. A clean dataframe to be run through the model. \n",
    "2. A dataframe of the dropped observations to be rejoined to model predictions. This allows for the data to be reshaped to a 2D numpy array and written as a raster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(df, target):\n",
    "    \"\"\"\n",
    "    Prepares data to run model on.\n",
    "    Input: \n",
    "    - A dataframe containing created using the flattened numpy arrays returned from reading in the raster chunks. \n",
    "    Returns: \n",
    "    - Clean dataframe without NULL data or non-burnable F40 Classes \n",
    "    - Dataframe with the dropped observations - to be reappended after prediction\n",
    "    \"\"\"\n",
    "    # Based on the target, rename the dropped LF column to Pred column\n",
    "    column_dict = {\n",
    "        \"LF22_F40\" : {'LF20_F40' : 'F40_Pred'},\n",
    "        \"LF22_FVC\" : {\"LF20_FVC\" : \"FVC_Pred\"},\n",
    "        \"LF22_FVH\" : {\"LF20_FVH\" : \"FVH_Pred\"},\n",
    "        \"LF22_FVT\" : {\"LF20_FVT\" : \"FVT_Pred\"}\n",
    "    }\n",
    "\n",
    "    pred_dict = {\n",
    "        \"LF22_F40\" : \"F40_Pred\",\n",
    "        \"LF22_FVC\" : \"FVC_Pred\",\n",
    "        \"LF22_FVH\" : \"FVH_Pred\",\n",
    "        \"LF22_FVT\" : \"FVT_Pred\"\n",
    "    }\n",
    "\n",
    "    if target != 'LF22_F40':\n",
    "        df = join_features(df, feature_list = ['BPS_NAME'])\n",
    "\n",
    "    # Remove -9999/-1111 (Null values)\n",
    "    null = df[(df.isin([-1111, -9999, -32768])).any(axis=1)]  # Find rows with -1111/-9999 in any column\n",
    "    df = df.drop(null.index, axis=0)  # Drop those rows\n",
    "\n",
    "    # Drop non-disturbed values if not predicting F40\n",
    "    if target != 'LF22_F40':\n",
    "        non_disturbed = df.loc[df['LF22_FDST'] == 0]\n",
    "        df = df.drop(non_disturbed.index, axis=0)\n",
    "\n",
    "    # Filter classes based on the target\n",
    "    if target == 'LF22_F40':\n",
    "        # Remove Non-Burnable Classes\n",
    "        F40_NB = [91, 93]  # Nonburnable F40 Classes\n",
    "        filtered = df.loc[df['LF20_F40'].isin(F40_NB)]  # Drop NB classes\n",
    "        df = df.drop(filtered.index, axis=0)\n",
    "        \n",
    "    elif target == 'LF22_FVC':\n",
    "        fvc_filter = list(range(20, 70)) + list(range(80, 86))\n",
    "        filtered = df.loc[df['LF20_FVC'].isin(fvc_filter)]\n",
    "        df = df.drop(filtered.index, axis=0)\n",
    "    \n",
    "    elif target == 'LF22_FVH':\n",
    "        fvh_filter = list(range(20, 70)) + list(range(80, 86))\n",
    "        filtered = df.loc[df['LF20_FVH'].isin(fvh_filter)]\n",
    "        df = df.drop(filtered.index, axis=0)\n",
    "\n",
    "    elif target == 'LF22_FVT':\n",
    "        # Filter out agricultural and developed points\n",
    "        developed_fvt = list(range(20,33)) + list(range(2901,2906))\n",
    "        ag_fvt = [80, 81, 82] + list(range(2960, 2971))\n",
    "        fvt_filter = developed_fvt + ag_fvt\n",
    "        filtered = df.loc[df['LF20_FVT'].isin(fvt_filter)]\n",
    "        df = df.drop(filtered.index, axis=0)\n",
    "\n",
    "    # Join the filtered values together so they can be readded later\n",
    "    if target == 'LF22_F40':\n",
    "        dropped = pd.concat([null, filtered], axis=0)\n",
    "        dropped = dropped.rename(columns=column_dict[target])\n",
    "    else:\n",
    "        dropped = pd.concat([null, non_disturbed, filtered], axis=0)\n",
    "        dropped = dropped.rename(columns=column_dict[target])\n",
    "\n",
    "    \n",
    "    return df, dropped[pred_dict[target]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window Read Function\n",
    "This function is used to read in chunks of the rull raster to be processed. The raster data is stored as blocks with height=1 and width=41855 (the raster width), so we read in chunks composed of these blocks (e.g. 1000 blocks at a time). This corresponds to the row_slice argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_read(ras, row_slice):\n",
    "  \"\"\"\n",
    "  Reads in a subset (window) of the data to be processed.\n",
    "  Inputs:\n",
    "  - ras: Raster object read in using rasterio\n",
    "  - row_slice: Used to define the window height - in the form (row_start, row_end). \n",
    "\n",
    "  Returns:\n",
    "  - data: The data in the window as a 2D numpy array\n",
    "  - win: The Window object used to define the subset of the data. \n",
    "  - win_transform: The affine transform associated with the window. Used to update the metadata of the output of that chunk. \n",
    "  \"\"\"\n",
    "  \n",
    "  with rasterio.open(ras) as src:\n",
    "    col_slice = (0, src.width)  # Define row slice based on block size\n",
    "    win = Window.from_slices(row_slice, col_slice) \n",
    "    data = src.read(window=win)\n",
    "    win_transform = src.window_transform(win)\n",
    "    \n",
    "  return data, win, win_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Apply Trained Model__ \n",
    "Applies a trained model to the prepared data to predict FVT for each observation (i.e. pixel). After making predictions, rejoins the previously dropped observations so that the dataframe can be reshaped to a 2D numpy array and written to a raster. The index is used to keep track of relative pixel locations in the dataframe. This function returns a dataframe with predictions for each non-null and burnable observation. \n",
    "\n",
    "The model was not trained using null (-9999, -1111), non-disturbed, or agricultural/developed classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_raster(model, df, target):\n",
    "    \"\"\"\n",
    "    Predicts F40 class given a trained model and data to predict on.\n",
    "    Returns:\n",
    "    - A dataframe of predicted F40 values joined to the previously dropped values. \n",
    "    \"\"\"\n",
    "    # Specify output variable name as function of target\n",
    "    var_name_dict = {\n",
    "        \"LF22_F40\" : \"F40_Pred\",\n",
    "        \"LF22_FVC\" : \"FVC_Pred\",\n",
    "        \"LF22_FVH\" : \"FVH_Pred\",\n",
    "        \"LF22_FVT\" : \"FVT_Pred\",\n",
    "    }\n",
    "\n",
    "    # Prep the data - get the a clean dataframe (i.e. no NULL data/nonburnable classes) and dropped observations\n",
    "    clean_df, dropped = data_prep(df, target)\n",
    "\n",
    "    # Get list of predictors for run\n",
    "    predictors = list(model.feature_names_in_)\n",
    "    \n",
    "    X = clean_df[predictors].copy()\n",
    "\n",
    "    # Run model to predict\n",
    "    # If clean_df is empty, then all values were NULL and are in dropped\n",
    "    if clean_df.shape[0] > 0:\n",
    "        y_pred = model.predict(X)\n",
    "    else:\n",
    "        return dropped\n",
    "    \n",
    "    # Join the dropped observations back in \n",
    "    # This allows the result dataframe to be reshaped back to a raster\n",
    "    df = pd.DataFrame({var_name_dict[target] : y_pred},\n",
    "                       index=X.index)\n",
    "    df = pd.concat([dropped, df])\n",
    "    df.sort_index(inplace=True)\n",
    "\n",
    "    # Return predictions\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_predict(row, target, model_fpath, win_height, raster_dict, ras_shape, out_dir, out_meta):\n",
    "\n",
    "    model = load(model_fpath)\n",
    "\n",
    "    row_start = row\n",
    "    row_end = row + win_height  # This is also the row_offset of the window\n",
    "\n",
    "    # make sure slice doesn't exceed row/col dims\n",
    "    if row_end > ras_shape[0]:\n",
    "        row_end = ras_shape[0]\n",
    "\n",
    "    # Define the window to be processed\n",
    "    row_slice = (row_start, row_end)\n",
    "\n",
    "    data_dict = {}\n",
    "\n",
    "    # For the current window, load data from each rasters\n",
    "    for var, fpath in raster_dict.items():\n",
    "        data_chunk, data_win, data_transform = windowed_read(fpath, row_slice)\n",
    "        data_dict[var] = data_chunk.ravel()\n",
    "\n",
    "    # Create a dataframe from the dictionary of datachunks\n",
    "    df = pd.DataFrame(data_dict)\n",
    "\n",
    "    # Look at the window currently processing\n",
    "    clear_output()\n",
    "\n",
    "    datetime = dt.datetime.now().strftime('%H-%M-%S-%f')\n",
    "    out_file = f\"data_chunk_{datetime}.tif\"\n",
    "    #print(f\"Row Slice: {row_slice}\")  \n",
    "    #print(f\"Writing {out_file}.\")\n",
    "    #print(f\"Processing window {i} of {floor(ras.shape[0] / win_height)}\")\n",
    "\n",
    "    # Run model to predict F40 Classes for window \n",
    "    out_arr = predict_raster(model, df, target)\n",
    "\n",
    "    # Reshape to 2D\n",
    "    out_arr_np = out_arr.to_numpy()\n",
    "    out_arr_2D = out_arr_np.reshape(data_chunk.shape)\n",
    "    out_arr_2D = out_arr_2D[0]\n",
    "\n",
    "    # update output metadata for chunk\n",
    "    out_meta.update({\n",
    "        'height': out_arr_2D.shape[0],\n",
    "        'width': out_arr_2D.shape[1],\n",
    "        'transform' : data_transform\n",
    "    })\n",
    "\n",
    "    # Write chunk out\n",
    "    datetime = dt.datetime.now().strftime('%H-%M-%S-%f')\n",
    "    out_file = f\"data_chunk_{datetime}.tif\"\n",
    "    with rasterio.open(os.path.join(out_dir, out_file), 'w+', **out_meta) as out:\n",
    "        out.write(out_arr_2D, indexes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(target, raster_fpaths_dict):\n",
    "  raster_fpaths = raster_fpaths_dict\n",
    "\n",
    "  # Define the model to import\n",
    "  model_fpath = models_fpath_dict[target]\n",
    "\n",
    "  # Arbitrarily grab metadata from raster to use for updating output metdata\n",
    "  with rasterio.open(raster_fpaths['LF20_F40']) as src:\n",
    "    out_meta = src.meta.copy()\n",
    "\n",
    "  # Open a raster to access its attributes\n",
    "  ras = rasterio.open(raster_fpaths['LF20_F40'])\n",
    "\n",
    "  # Create directory using current datetime to output data chunks to\n",
    "  datetime = dt.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')  # Used to name output file\n",
    "  out_dir = make_dir(base_dir=out_chunk_dir, file_name=out_fname_dict[target])\n",
    "\n",
    "  # Define window height and iteration tracker\n",
    "  win_height = 1000  # Number of rows to process at once\n",
    "\n",
    "  Parallel(n_jobs=24)(delayed(window_predict)(row, target, model_fpath, win_height, raster_fpaths, ras.shape, out_dir, out_meta) for row in range(0, ras.shape[0], win_height))\n",
    "  #for row in range(0, ras.shape[0], win_height):\n",
    "  #   window_predict(row, target, model_fpath, win_height, raster_fpaths, ras.shape, out_dir, out_meta)\n",
    "\n",
    "  ## Mosaic the data chunks\n",
    "  # Get the file paths of the generated data chunks\n",
    "  raster_fpaths = glob.glob(out_dir + \"/*.tif\")\n",
    "\n",
    "  # Get the rasterio dataset objects corresponding to each path\n",
    "  src_files_to_mosaic = []\n",
    "  for fpath in raster_fpaths:\n",
    "      src = rasterio.open(fpath)\n",
    "      src_files_to_mosaic.append(src)\n",
    "\n",
    "  # Merge the data chunks into a single raster\n",
    "  mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "\n",
    "  # Get the metadata for writing\n",
    "  out_meta = src.meta.copy()\n",
    "  out_meta.update({\n",
    "      \"driver\" : \"GTiff\",\n",
    "      \"height\" : mosaic.shape[1],\n",
    "      \"width\" : mosaic.shape[2],\n",
    "      \"transform\" : out_trans\n",
    "  })\n",
    "\n",
    "  # Write out the mosaic raster\n",
    "\n",
    "  fname = f\"{out_fname_dict[target] + \"_\" + datetime}.tif\"\n",
    "  with rasterio.open(os.path.join(out_raster_dir, fname), \"w\", **out_meta) as dest:\n",
    "      dest.write(mosaic)\n",
    "\n",
    "  print(f\"Raster written to {os.path.join(out_raster_dir, fname)}\")\n",
    "  return os.path.join(out_raster_dir, fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model Predictions\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pred_fvt_path \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLF22_FVT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraster_fpaths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m raster_fpaths[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLF22_FVT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pred_fvt_path\n\u001b[0;32m      5\u001b[0m targets \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLF22_FVH\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLF22_FVC\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[1;32mIn[10], line 23\u001b[0m, in \u001b[0;36mrun_model\u001b[1;34m(target, raster_fpaths_dict)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#Parallel(n_jobs=24)(delayed(window_predict)(row, target, model_fpath, win_height, raster_fpaths, ras.shape, out_dir, out_meta) for row in range(0, ras.shape[0], win_height))\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, ras\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], win_height):\n\u001b[1;32m---> 23\u001b[0m    \u001b[43mwindow_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_fpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwin_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraster_fpaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_meta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m## Mosaic the data chunks\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Get the file paths of the generated data chunks\u001b[39;00m\n\u001b[0;32m     27\u001b[0m raster_fpaths \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(out_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/*.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 35\u001b[0m, in \u001b[0;36mwindow_predict\u001b[1;34m(row, target, model_fpath, win_height, raster_dict, ras_shape, out_dir, out_meta)\u001b[0m\n\u001b[0;32m     29\u001b[0m out_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_chunk_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#print(f\"Row Slice: {row_slice}\")  \u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#print(f\"Writing {out_file}.\")\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#print(f\"Processing window {i} of {floor(ras.shape[0] / win_height)}\")\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Run model to predict F40 Classes for window \u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m out_arr \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_raster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Reshape to 2D\u001b[39;00m\n\u001b[0;32m     38\u001b[0m out_arr_np \u001b[38;5;241m=\u001b[39m out_arr\u001b[38;5;241m.\u001b[39mto_numpy()\n",
      "Cell \u001b[1;32mIn[8], line 26\u001b[0m, in \u001b[0;36mpredict_raster\u001b[1;34m(model, df, target)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Run model to predict\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# If clean_df is empty, then all values were NULL and are in dropped\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clean_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 26\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dropped\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\geospatial\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:2142\u001b[0m, in \u001b[0;36mHistGradientBoostingClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   2129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict classes for X.\u001b[39;00m\n\u001b[0;32m   2130\u001b[0m \n\u001b[0;32m   2131\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2139\u001b[0m \u001b[38;5;124;03m    The predicted classes.\u001b[39;00m\n\u001b[0;32m   2140\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2141\u001b[0m \u001b[38;5;66;03m# TODO: This could be done in parallel\u001b[39;00m\n\u001b[1;32m-> 2142\u001b[0m encoded_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   2143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[encoded_classes]\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\geospatial\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:2180\u001b[0m, in \u001b[0;36mHistGradientBoostingClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   2167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   2168\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict class probabilities for X.\u001b[39;00m\n\u001b[0;32m   2169\u001b[0m \n\u001b[0;32m   2170\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2178\u001b[0m \u001b[38;5;124;03m        The class probabilities of the input samples.\u001b[39;00m\n\u001b[0;32m   2179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2180\u001b[0m     raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss\u001b[38;5;241m.\u001b[39mpredict_proba(raw_predictions)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\geospatial\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:1280\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting._raw_predict\u001b[1;34m(self, X, n_threads)\u001b[0m\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;66;03m# We intentionally decouple the number of threads used at prediction\u001b[39;00m\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;66;03m# time from the number of threads used at fit time because the model\u001b[39;00m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;66;03m# can be deployed on a different machine for prediction purposes.\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m n_threads \u001b[38;5;241m=\u001b[39m _openmp_effective_n_threads(n_threads)\n\u001b[1;32m-> 1280\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_iterations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predictors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_binned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\n\u001b[0;32m   1282\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m raw_predictions\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\geospatial\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:1308\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting._predict_iterations\u001b[1;34m(self, X, predictors, raw_predictions, is_binned, n_threads)\u001b[0m\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1302\u001b[0m     predict \u001b[38;5;241m=\u001b[39m partial(\n\u001b[0;32m   1303\u001b[0m         predictor\u001b[38;5;241m.\u001b[39mpredict,\n\u001b[0;32m   1304\u001b[0m         known_cat_bitsets\u001b[38;5;241m=\u001b[39mknown_cat_bitsets,\n\u001b[0;32m   1305\u001b[0m         f_idx_map\u001b[38;5;241m=\u001b[39mf_idx_map,\n\u001b[0;32m   1306\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[0;32m   1307\u001b[0m     )\n\u001b[1;32m-> 1308\u001b[0m raw_predictions[:, k] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\geospatial\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\predictor.py:69\u001b[0m, in \u001b[0;36mTreePredictor.predict\u001b[1;34m(self, X, known_cat_bitsets, f_idx_map, n_threads)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict raw values for non-binned data.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    The raw predicted values.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mY_DTYPE)\n\u001b[1;32m---> 69\u001b[0m \u001b[43m_predict_from_raw_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_left_cat_bitsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mknown_cat_bitsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf_idx_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pred_fvt_path = run_model('LF22_FVT', raster_fpaths)\n",
    "raster_fpaths['LF22_FVT'] = pred_fvt_path\n",
    "\n",
    "\n",
    "targets = [\"LF22_FVH\", \"LF22_FVC\"]\n",
    "pred_fpaths = {}\n",
    "\n",
    "for target in targets:\n",
    "    print(f\"Processing {target}...\")\n",
    "    pred_fpaths[target] = run_model(target, raster_fpaths)\n",
    "\n",
    "# Update raster_fpaths using the predicted raster paths\n",
    "for raster, fpath in pred_fpaths.items():\n",
    "    raster_fpaths[raster] = fpath\n",
    "\n",
    "print(\"Processing F40...\")\n",
    "run_model(\"LF22_F40\", raster_fpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Just run the F40 model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing F40...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLF22_F40\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraster_fpaths\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 23\u001b[0m, in \u001b[0;36mrun_model\u001b[1;34m(target, raster_fpaths_dict)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#Parallel(n_jobs=24)(delayed(window_predict)(row, target, model_fpath, win_height, raster_fpaths, ras.shape, out_dir, out_meta) for row in range(0, ras.shape[0], win_height))\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, ras\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], win_height):\n\u001b[1;32m---> 23\u001b[0m    \u001b[43mwindow_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_fpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwin_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraster_fpaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_meta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m## Mosaic the data chunks\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Get the file paths of the generated data chunks\u001b[39;00m\n\u001b[0;32m     27\u001b[0m raster_fpaths \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(out_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/*.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[20], line 35\u001b[0m, in \u001b[0;36mwindow_predict\u001b[1;34m(row, target, model_fpath, win_height, raster_dict, ras_shape, out_dir, out_meta)\u001b[0m\n\u001b[0;32m     29\u001b[0m out_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_chunk_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#print(f\"Row Slice: {row_slice}\")  \u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#print(f\"Writing {out_file}.\")\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#print(f\"Processing window {i} of {floor(ras.shape[0] / win_height)}\")\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Run model to predict F40 Classes for window \u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m out_arr \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_raster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Reshape to 2D\u001b[39;00m\n\u001b[0;32m     38\u001b[0m out_arr_np \u001b[38;5;241m=\u001b[39m out_arr\u001b[38;5;241m.\u001b[39mto_numpy()\n",
      "Cell \u001b[1;32mIn[19], line 16\u001b[0m, in \u001b[0;36mpredict_raster\u001b[1;34m(model, df, target)\u001b[0m\n\u001b[0;32m      8\u001b[0m var_name_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLF22_F40\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF40_Pred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLF22_FVC\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFVC_Pred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLF22_FVH\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFVH_Pred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLF22_FVT\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFVT_Pred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m }\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Prep the data - get the a clean dataframe (i.e. no NULL data/nonburnable classes) and dropped observations\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m clean_df, dropped \u001b[38;5;241m=\u001b[39m \u001b[43mdata_prep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Get list of predictors for run\u001b[39;00m\n\u001b[0;32m     19\u001b[0m predictors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(model\u001b[38;5;241m.\u001b[39mfeature_names_in_)\n",
      "Cell \u001b[1;32mIn[17], line 29\u001b[0m, in \u001b[0;36mdata_prep\u001b[1;34m(df, target)\u001b[0m\n\u001b[0;32m     26\u001b[0m     df \u001b[38;5;241m=\u001b[39m join_features(df, feature_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBPS_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Remove -9999/-1111 (Null values)\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m null \u001b[38;5;241m=\u001b[39m df[(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1111\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m9999\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m32768\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39many(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]  \u001b[38;5;66;03m# Find rows with -1111/-9999 in any column\u001b[39;00m\n\u001b[0;32m     30\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(null\u001b[38;5;241m.\u001b[39mindex, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Drop those rows\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Drop non-disturbed values if not predicting F40\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\geospatial\\Lib\\site-packages\\pandas\\core\\frame.py:12468\u001b[0m, in \u001b[0;36mDataFrame.isin\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m  12462\u001b[0m         result \u001b[38;5;241m=\u001b[39m algorithms\u001b[38;5;241m.\u001b[39misin(\n\u001b[0;32m  12463\u001b[0m             x\u001b[38;5;241m.\u001b[39mravel(),\n\u001b[0;32m  12464\u001b[0m             values,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m  12465\u001b[0m         )\n\u001b[0;32m  12466\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m> 12468\u001b[0m     res_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43misin_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  12469\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(\n\u001b[0;32m  12470\u001b[0m         res_mgr,\n\u001b[0;32m  12471\u001b[0m         axes\u001b[38;5;241m=\u001b[39mres_mgr\u001b[38;5;241m.\u001b[39maxes,\n\u001b[0;32m  12472\u001b[0m     )\n\u001b[0;32m  12473\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\geospatial\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:361\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    358\u001b[0m             kwargs[k] \u001b[38;5;241m=\u001b[39m obj[b\u001b[38;5;241m.\u001b[39mmgr_locs\u001b[38;5;241m.\u001b[39mindexer]\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(f):\n\u001b[1;32m--> 361\u001b[0m     applied \u001b[38;5;241m=\u001b[39m \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    363\u001b[0m     applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\geospatial\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:393\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\geospatial\\Lib\\site-packages\\pandas\\core\\frame.py:12462\u001b[0m, in \u001b[0;36mDataFrame.isin.<locals>.isin_\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m  12457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misin_\u001b[39m(x):\n\u001b[0;32m  12458\u001b[0m     \u001b[38;5;66;03m# error: Argument 2 to \"isin\" has incompatible type \"Union[Series,\u001b[39;00m\n\u001b[0;32m  12459\u001b[0m     \u001b[38;5;66;03m# DataFrame, Sequence[Any], Mapping[Any, Any]]\"; expected\u001b[39;00m\n\u001b[0;32m  12460\u001b[0m     \u001b[38;5;66;03m# \"Union[Union[Union[ExtensionArray, ndarray[Any, Any]], Index,\u001b[39;00m\n\u001b[0;32m  12461\u001b[0m     \u001b[38;5;66;03m# Series], List[Any], range]\"\u001b[39;00m\n\u001b[1;32m> 12462\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  12463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  12464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m  12465\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  12466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\geospatial\\Lib\\site-packages\\pandas\\core\\algorithms.py:545\u001b[0m, in \u001b[0;36misin\u001b[1;34m(comps, values)\u001b[0m\n\u001b[0;32m    542\u001b[0m     comps_array \u001b[38;5;241m=\u001b[39m comps_array\u001b[38;5;241m.\u001b[39mastype(common, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    543\u001b[0m     f \u001b[38;5;241m=\u001b[39m htable\u001b[38;5;241m.\u001b[39mismember\n\u001b[1;32m--> 545\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomps_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\geospatial\\Lib\\site-packages\\pandas\\core\\algorithms.py:537\u001b[0m, in \u001b[0;36misin.<locals>.<lambda>\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlogical_or(np\u001b[38;5;241m.\u001b[39misin(c, v)\u001b[38;5;241m.\u001b[39mravel(), np\u001b[38;5;241m.\u001b[39misnan(c))\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 537\u001b[0m         f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m a, b: \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    540\u001b[0m     common \u001b[38;5;241m=\u001b[39m np_find_common_type(values\u001b[38;5;241m.\u001b[39mdtype, comps_array\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\geospatial\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:890\u001b[0m, in \u001b[0;36misin\u001b[1;34m(element, test_elements, assume_unique, invert, kind)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;124;03mCalculates ``element in test_elements``, broadcasting over `element` only.\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;124;03mReturns a boolean array of the same shape as `element` that is True\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;124;03m       [ True, False]])\u001b[39;00m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    889\u001b[0m element \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(element)\n\u001b[1;32m--> 890\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43min1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_elements\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massume_unique\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massume_unique\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m            \u001b[49m\u001b[43minvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(element\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Just run the F40 model\n",
    "print(\"Processing F40...\")\n",
    "run_model(\"LF22_F40\", raster_fpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LF20_F40': '\\\\\\\\pnl\\\\projects\\\\BPAWildfire\\\\data\\\\Landfire\\\\fuels_modeling\\\\fuelscape_modeling\\\\..\\\\LF_raster_data\\\\bpa_service_territory\\\\LC22_F40_220_bpa.tif', 'LF20_FVT': '\\\\\\\\pnl\\\\projects\\\\BPAWildfire\\\\data\\\\Landfire\\\\fuels_modeling\\\\fuelscape_modeling\\\\..\\\\LF_raster_data\\\\bpa_service_territory\\\\LC22_FVT_220_bpa.tif', 'LF22_FVT': '\\\\\\\\pnl\\\\projects\\\\BPAWildfire\\\\data\\\\Landfire\\\\fuels_modeling\\\\LF_raster_data\\\\bpa_service_territory\\\\_predicted_rasters\\\\Pred_LF22_FVT_2024-05-29_14-59-45.tif', 'LF20_FVC': '\\\\\\\\pnl\\\\projects\\\\BPAWildfire\\\\data\\\\Landfire\\\\fuels_modeling\\\\fuelscape_modeling\\\\..\\\\LF_raster_data\\\\bpa_service_territory\\\\LC22_FVC_220_bpa.tif', 'LF22_FVC': '\\\\\\\\pnl\\\\projects\\\\BPAWildfire\\\\data\\\\Landfire\\\\fuels_modeling\\\\LF_raster_data\\\\bpa_service_territory\\\\_predicted_rasters\\\\Pred_LF22_FVC_2024-05-29_14-19-39.tif', 'LF20_FVH': '\\\\\\\\pnl\\\\projects\\\\BPAWildfire\\\\data\\\\Landfire\\\\fuels_modeling\\\\fuelscape_modeling\\\\..\\\\LF_raster_data\\\\bpa_service_territory\\\\LC22_FVH_220_bpa.tif', 'LF22_FVH': '\\\\\\\\pnl\\\\projects\\\\BPAWildfire\\\\data\\\\Landfire\\\\fuels_modeling\\\\LF_raster_data\\\\bpa_service_territory\\\\_predicted_rasters\\\\Pred_LF22_FVH_2024-05-29_13-49-26.tif', 'LF22_FDST': '\\\\\\\\pnl\\\\projects\\\\BPAWildfire\\\\data\\\\Landfire\\\\fuels_modeling\\\\fuelscape_modeling\\\\..\\\\LF_raster_data\\\\bpa_service_territory\\\\LC22_FDst_230_bpa.tif', 'BPS': '\\\\\\\\pnl\\\\projects\\\\BPAWildfire\\\\data\\\\Landfire\\\\fuels_modeling\\\\fuelscape_modeling\\\\..\\\\LF_raster_data\\\\bpa_service_territory\\\\LC20_BPS_220_bpa.tif', 'ZONE': '\\\\\\\\pnl\\\\projects\\\\BPAWildfire\\\\data\\\\Landfire\\\\fuels_modeling\\\\fuelscape_modeling\\\\..\\\\LF_raster_data\\\\bpa_service_territory\\\\us_lf_zones_bpa.tif', 'ASPECT': '\\\\\\\\pnl\\\\projects\\\\BPAWildfire\\\\data\\\\Landfire\\\\fuels_modeling\\\\fuelscape_modeling\\\\..\\\\LF_raster_data\\\\bpa_service_territory\\\\LC20_Asp_220_bpa.tif', 'SLOPE': '\\\\\\\\pnl\\\\projects\\\\BPAWildfire\\\\data\\\\Landfire\\\\fuels_modeling\\\\fuelscape_modeling\\\\..\\\\LF_raster_data\\\\bpa_service_territory\\\\LC20_SlpD_220_bpa.tif', 'ELEVATION': '\\\\\\\\pnl\\\\projects\\\\BPAWildfire\\\\data\\\\Landfire\\\\fuels_modeling\\\\fuelscape_modeling\\\\..\\\\LF_raster_data\\\\bpa_service_territory\\\\LC20_Elev_220_bpa.tif', 'BPS_FRG_NE': '\\\\\\\\pnl\\\\projects\\\\BPAWildfire\\\\data\\\\Landfire\\\\fuels_modeling\\\\fuelscape_modeling\\\\..\\\\LF_raster_data\\\\bpa_service_territory\\\\BPS_FRG_NEW.tif'}\n",
      "Processing F40...\n",
      "Raster written to \\\\pnl\\projects\\BPAWildfire\\data\\Landfire\\fuels_modeling\\fuelscape_modeling\\outputs\\geospatial\\Pred_LF22_F40_2024-05-29_18-41-00\\Pred_LF22_F40_2024-05-29_18-41-00.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\\\\\\\pnl\\\\projects\\\\BPAWildfire\\\\data\\\\Landfire\\\\fuels_modeling\\\\fuelscape_modeling\\\\outputs\\\\geospatial\\\\Pred_LF22_F40_2024-05-29_18-41-00\\\\Pred_LF22_F40_2024-05-29_18-41-00.tif'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_fpaths = {\n",
    "    'LF22_FVH' : r\"\\\\pnl\\projects\\BPAWildfire\\data\\Landfire\\fuels_modeling\\LF_raster_data\\bpa_service_territory\\_predicted_rasters\\Pred_LF22_FVH_2024-05-29_13-49-26.tif\",\n",
    "    'LF22_FVC' : r\"\\\\pnl\\projects\\BPAWildfire\\data\\Landfire\\fuels_modeling\\LF_raster_data\\bpa_service_territory\\_predicted_rasters\\Pred_LF22_FVC_2024-05-29_14-19-39.tif\",\n",
    "    'LF22_FVT' : r\"\\\\pnl\\projects\\BPAWildfire\\data\\Landfire\\fuels_modeling\\LF_raster_data\\bpa_service_territory\\_predicted_rasters\\Pred_LF22_FVT_2024-05-29_14-59-45.tif\"\n",
    "}\n",
    "\n",
    "# Update raster_fpaths using the predicted raster paths\n",
    "for raster, fpath in pred_fpaths.items():\n",
    "    raster_fpaths[raster] = fpath\n",
    "\n",
    "print(raster_fpaths)\n",
    "print(\"Processing F40...\")\n",
    "run_model(\"LF22_F40\", raster_fpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LF22_F40\n",
      "['LF22_FVT' 'LF22_FVH' 'LF22_FVC' 'LF22_FDST' 'ZONE' 'BPS_FRG_NE']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LF22_FVT\n",
      "['LF20_FVT' 'LF22_FDST' 'ZONE' 'ASPECT' 'SLOPE' 'ELEVATION' 'BPS_NAME'\n",
      " 'LF20_FVC' 'LF20_FVH']\n",
      "LF22_FVC\n",
      "['LF22_FVT' 'LF20_FVC' 'LF22_FDST' 'ZONE' 'BPS_NAME']\n",
      "LF22_FVH\n",
      "['LF22_FVT' 'LF20_FVH' 'LF22_FDST' 'ZONE' 'BPS_NAME']\n"
     ]
    }
   ],
   "source": [
    "for var, path in models_fpath_dict.items():\n",
    "    model = load(path)\n",
    "    print(var)\n",
    "    print(model.feature_names_in_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
