{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABOUT\n",
    "__Author__: Pat McCornack\n",
    "\n",
    "__Date__: 3/21/2024\n",
    "\n",
    "__Purpose:__ Script to apply a trained model to predict FBFM40 values. Outputs a raster of predicted FBFM40 values across the bpa service territory. \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.windows import Window\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from joblib import load\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define filepaths\n",
    "active_root_dir = r\"C:\\Users\\mcco573\\OneDrive - PNNL\\Documents\\_Projects\\BPA Wildfire\\F40_modeling\"\n",
    "pnnl_root_dir = r\"\\\\pnl\\projects\\BPAWildfire\\data\\Landfire\\fuels_modeling\\F40_modeling\"\n",
    "\n",
    "# Choose whether to work from local or drive\n",
    "active_root_dir = pnnl_root_dir\n",
    "\n",
    "paths_dict = {\n",
    "    'output_dir' : os.path.join(active_root_dir, r'model_outputs\\geospatial\\_bpa_service_territory'),\n",
    "    'data_dir' : os.path.join(active_root_dir, r'..\\LF_raster_data\\bpa_service_territory'),\n",
    "    'model_dir' : os.path.join(active_root_dir, 'models'),\n",
    "    'model_fname' : 'LF22_F40_model_2024-05-15_15-21-33',\n",
    "    'out_fname' : \"LF22_F40_Pred_with_Pred_FVT\" + \"_\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Directory\n",
    "Creates a directory where data will be output - labeled with the datetime that the script is run. Returns name of directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess window dataframe\n",
    "Prepares the data to be run through the model. Separates out null and non-burnable values. Returns a dictionary with: \n",
    "1. A clean dataframe to be run through the model. \n",
    "2. A dataframe of the dropped observations to be rejoined to model predictions. This allows for the data to be reshaped to a 2D numpy array and written as a raster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir(base_dir, file_name):\n",
    "        \"\"\"\n",
    "        Create a directory named using the current datetime.\n",
    "        Returns:\n",
    "        - Name of the directory as a string\n",
    "        \"\"\"\n",
    "\n",
    "        datetime = dt.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        output_dir = os.path.join(base_dir, file_name + datetime)\n",
    "\n",
    "        os.makedirs(output_dir)\n",
    "        return output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(df, target='LF22_F40'):\n",
    "    \"\"\"\n",
    "    Prepares data to run model on.\n",
    "    Input: \n",
    "    - A dataframe containing created using the flattened numpy arrays returned from reading in the raster chunks. \n",
    "    Returns: \n",
    "    - Clean dataframe without NULL data or non-burnable F40 Classes \n",
    "    - Dataframe with the dropped observations - to be reappended after prediction\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove -9999/-1111 (Null values)\n",
    "    dropped = df[(df.isin([-1111, -9999])).any(axis=1)]  # Find rows with -1111/-9999 in any column\n",
    "    df = df.drop(dropped.index, axis=0)  # Drop those rows\n",
    "\n",
    "    # Set the F40 value for dropped rows to Null\n",
    "    dropped['F40_Pred'] = -9999\n",
    "    \n",
    "    return {\"clean_df\": df,\n",
    "            \"dropped_obs\": dropped['F40_Pred']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window Read Function\n",
    "This function is used to read in chunks of the rull raster to be processed. The raster data is stored as blocks with height=1 and width=41854 (the raster width), so we read in chunks composed of these blocks (e.g. 1000 blocks at a time). This corresponds to the row_slice argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_read(ras, row_slice):\n",
    "  \"\"\"\n",
    "  Reads in a subset (window) of the data to be processed.\n",
    "  Inputs:\n",
    "  - ras: Raster object read in using rasterio\n",
    "  - row_slice: Used to define the window height - in the form (row_start, row_end). \n",
    "\n",
    "  Returns:\n",
    "  - data: The data in the window as a 2D numpy array\n",
    "  - win: The Window object used to define the subset of the data. \n",
    "  - win_transform: The affine transform associated with the window. Used to update the metadata of the output of that chunk. \n",
    "  \"\"\"\n",
    "  \n",
    "  with rasterio.open(ras) as src:\n",
    "    col_slice = (0, src.width)  # Define row slice based on block size\n",
    "    win = Window.from_slices(row_slice, col_slice) \n",
    "    data = src.read(window=win)\n",
    "    win_transform = src.window_transform(win)\n",
    "    \n",
    "  return data, win, win_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using trained model\n",
    "Applies a trained model to the prepared data to predict F40 for each observation (i.e. pixel). After making predictions, rejoins the previously dropped observations so that the dataframe can be reshaped to a 2D numpy array and written to a raster. The index is used to keep track of relative pixel locations in the dataframe. This function returns a dataframe with predictions for each non-null and burnable observation. \n",
    "\n",
    "The model was not trained using null (-9999, -1111) or non-burnable classes. It is assumed that pixels with these values are static and would not be updated as a result of disturbance - hence removing them from the data passed to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_F40(model, df, target='LF22_F40'):\n",
    "    \"\"\"\n",
    "    Predicts F40 class given a trained model and data to predict on.\n",
    "    Returns:\n",
    "    - A dataframe of predicted F40 values joined to the previously dropped values. \n",
    "    \"\"\"\n",
    "    # Specify the target variable  \n",
    "\n",
    "    # Prep the data - get the a clean dataframe (i.e. no NULL data/nonburnable classes) and dropped observations\n",
    "    prep_data = data_prep(df)\n",
    "    clean_df = prep_data['clean_df']\n",
    "    dropped = prep_data['dropped_obs']\n",
    "\n",
    "    # Get list of predictors for run\n",
    "    predictors = clean_df.columns.tolist()\n",
    "    \n",
    "    x_test = clean_df[predictors].copy()\n",
    "\n",
    "    # Run model to predict\n",
    "    # If clean_df is empty, then all values were NULL and are in dropped\n",
    "    if clean_df.shape[0] > 0:\n",
    "        y_pred = model.predict(x_test)\n",
    "    else:\n",
    "        return dropped\n",
    "    \n",
    "    # Join the dropped observations back in \n",
    "    # This allows the result dataframe to be reshaped back to a raster\n",
    "    df = pd.DataFrame({\"F40_Pred\" : y_pred},\n",
    "                       index=x_test.index)\n",
    "    df = pd.concat([dropped, df])\n",
    "    df.sort_index(inplace=True)\n",
    "\n",
    "    print(df.head())\n",
    "\n",
    "    # Return predictions\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_predict(row, model_fpath, win_height, raster_dict, ras_shape, out_dir, out_meta):\n",
    "\n",
    "    model = load(model_fpath)\n",
    "\n",
    "    row_start = row\n",
    "    row_end = row + win_height  # This is also the row_offset of the window\n",
    "\n",
    "    # make sure slice doesn't exceed row/col dims\n",
    "    if row_end > ras_shape[0]:\n",
    "        row_end = ras_shape[0]\n",
    "\n",
    "    # Define the window to be processed\n",
    "    row_slice = (row_start, row_end)\n",
    "\n",
    "    data_dict = {}\n",
    "\n",
    "    # For the current window, load data from each rasters\n",
    "    for var, fpath in raster_dict.items():\n",
    "        data_chunk, data_win, data_transform = windowed_read(fpath, row_slice)\n",
    "        data_dict[var] = data_chunk.ravel()\n",
    "\n",
    "    # Create a dataframe from the dictionary of datachunks\n",
    "    df = pd.DataFrame(data_dict)\n",
    "\n",
    "    # Look at the window currently processing\n",
    "    clear_output()\n",
    "\n",
    "    datetime = dt.datetime.now().strftime('%H-%M-%S-%f')\n",
    "    out_file = f\"data_chunk_{datetime}.tif\"\n",
    "    #print(f\"Row Slice: {row_slice}\")  \n",
    "    #print(f\"Writing {out_file}.\")\n",
    "    #print(f\"Processing window {i} of {floor(ras.shape[0] / win_height)}\")\n",
    "\n",
    "    # Run model to predict F40 Classes for window \n",
    "    out_arr = predict_F40(model, df)\n",
    "\n",
    "    # Reshape to 2D\n",
    "    out_arr_np = out_arr.to_numpy()\n",
    "    out_arr_2D = out_arr_np.reshape(data_chunk.shape)\n",
    "    out_arr_2D = out_arr_2D[0]\n",
    "\n",
    "    # update output metadata for chunk\n",
    "    out_meta.update({\n",
    "    'height': out_arr_2D.shape[0],\n",
    "    'width': out_arr_2D.shape[1],\n",
    "    'transform' : data_transform\n",
    "    })\n",
    "\n",
    "    # Write chunk out\n",
    "    datetime = dt.datetime.now().strftime('%H-%M-%S-%f')\n",
    "    out_file = f\"data_chunk_{datetime}.tif\"\n",
    "    with rasterio.open(os.path.join(out_dir, out_file), 'w+', **out_meta) as out:\n",
    "        out.write(out_arr_2D, indexes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model Predictions\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target name\n",
    "target = 'LF22_F40'\n",
    "\n",
    "# Define the model to import\n",
    "model_fpath = os.path.join(paths_dict['model_dir'], paths_dict['model_fname'])\n",
    "\n",
    "# Define the source raster file names\n",
    "pred_FVT_fpath = r\"\\\\pnl\\projects\\BPAWildfire\\data\\Landfire\\fuels_modeling\\LF_raster_data\\bpa_service_territory\\_predicted_rasters\\LF22_Pred_FVT_2024-05-15_14-29-34.tif\"\n",
    "raster_paths = {\n",
    "    \"LF22_FVT\" : pred_FVT_fpath,\n",
    "    #\"LF22_FVT\" : os.path.join(paths_dict['data_dir'], \"LC22_FVT_230_bpa.tif\"),\n",
    "    \"LF22_FVC\" : os.path.join(paths_dict['data_dir'], \"LC22_FVC_230_bpa.tif\"),\n",
    "    \"LF22_FVH\" : os.path.join(paths_dict['data_dir'], \"LC22_FVH_230_bpa.tif\"),\n",
    "    \"LF22_FDST\" : os.path.join(paths_dict['data_dir'], \"LC22_FDst_230_bpa.tif\"),\n",
    "    \"ZONE\" : os.path.join(paths_dict['data_dir'], \"us_lf_zones_bpa.tif\"),\n",
    "    \"BPS_FRG_NE\" : os.path.join(paths_dict['data_dir'], \"BPS_FRG_bpa.tif\")\n",
    "}\n",
    "\n",
    "# Arbitrarily grab metadata from F40 raster to use for updating output metdata\n",
    "with rasterio.open(raster_paths['LF22_FVT']) as src:\n",
    "  out_meta = src.meta.copy()\n",
    "\n",
    "# Open a raster to access its attributes\n",
    "ras = rasterio.open(raster_paths['LF22_FVT'])\n",
    "\n",
    "# Create directory using current datetime to output data chunks to\n",
    "datetime = dt.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')  # Used to name output file\n",
    "out_dir = make_dir(base_dir=paths_dict['output_dir'], file_name=paths_dict['out_fname'])\n",
    "\n",
    "# Define window height and iteration tracker\n",
    "win_height = 1000  # Number of rows to process at once\n",
    "\n",
    "Parallel(n_jobs=24)(delayed(window_predict)(row, model_fpath, win_height, raster_paths, ras.shape, out_dir, out_meta) for row in range(0, ras.shape[0], win_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mosaic the Data Chunks\n",
    "Combines the chunks generated above into a single raster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file paths of the generated data chunks\n",
    "raster_fpaths = glob.glob(out_dir + \"/*.tif\")\n",
    "\n",
    "# Get the rasterio dataset objects corresponding to each path\n",
    "src_files_to_mosaic = []\n",
    "for fpath in raster_fpaths:\n",
    "    src = rasterio.open(fpath)\n",
    "    src_files_to_mosaic.append(src)\n",
    "\n",
    "# Merge the data chunks into a single raster\n",
    "mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "\n",
    "# Get the metadata for writing\n",
    "out_meta = src.meta.copy()\n",
    "out_meta.update({\n",
    "    \"driver\" : \"GTiff\",\n",
    "    \"height\" : mosaic.shape[1],\n",
    "    \"width\" : mosaic.shape[2],\n",
    "    \"transform\" : out_trans\n",
    "})\n",
    "\n",
    "# Write out the mosaic raster\n",
    "fname = f\"{out_dir}_{datetime}.tif\"\n",
    "with rasterio.open(os.path.join(out_dir, fname), \"w\", **out_meta) as dest:\n",
    "    dest.write(mosaic)\n",
    "\n",
    "print(f\"Raster written to {os.path.join(out_dir, fname)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
